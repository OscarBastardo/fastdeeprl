{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa994ae-ee9b-4e46-afc3-06c3ab38feec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run a second experiment using the DQN algorithm\n",
    " \n",
    "- Allowed algorithm names can be found [here](https://docs.ray.io/en/master/rllib-algorithms.html)\n",
    "- To visualize both experiments together, use the same results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ceed762-e676-480c-814f-0c99b2d5c979",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.98',\n",
       " 'raylet_ip_address': '192.168.0.98',\n",
       " 'redis_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2022-12-23_17-04-52_551395_6000/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-12-23_17-04-52_551395_6000/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-12-23_17-04-52_551395_6000',\n",
       " 'metrics_export_port': 63737,\n",
       " 'gcs_address': '192.168.0.98:55832',\n",
       " 'address': '192.168.0.98:55832',\n",
       " 'node_id': '900dc007330a201ecbcdb5b146482f5cd82719c5075880be397ee651'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1961d539-2395-44c0-9bcd-d4586a229024",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQNTrainer pid=72303)\u001b[0m 2022-12-23 17:05:00,032\tINFO trainer.py:2140 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=72303)\u001b[0m 2022-12-23 17:05:00,032\tWARNING deprecation.py:45 -- DeprecationWarning: `evaluation_num_episodes` has been deprecated. Use ``evaluation_duration` and `evaluation_duration_unit=episodes`` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=72303)\u001b[0m 2022-12-23 17:05:00,032\tINFO simple_q.py:154 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=72303)\u001b[0m 2022-12-23 17:05:00,032\tINFO trainer.py:779 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=72303)\u001b[0m 2022-12-23 17:05:01,357\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:02 (running for 00:00:05.07)<br>Memory usage on this node: 4.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQNTrainer pid=72303)\u001b[0m 2022-12-23 17:05:02,592\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:03 (running for 00:00:06.08)<br>Memory usage on this node: 4.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-04\n",
      "  done: false\n",
      "  episode_len_mean: 24.65\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 87.0\n",
      "  episode_reward_mean: 24.65\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 40\n",
      "  episodes_total: 40\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 0.3717784881591797\n",
      "          mean_q: -0.06035442650318146\n",
      "          mean_td_error: -1.2911639213562012\n",
      "          min_q: -0.3929447829723358\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -1.1028194427490234\n",
      "        - -1.0722962617874146\n",
      "        - -1.3929448127746582\n",
      "        - -1.231927752494812\n",
      "        - -1.4425264596939087\n",
      "        - -1.0931023359298706\n",
      "        - -1.4172899723052979\n",
      "        - -1.324453353881836\n",
      "        - -1.064798355102539\n",
      "        - -1.3278765678405762\n",
      "        - -1.3805612325668335\n",
      "        - -1.8339605331420898\n",
      "        - -1.286409616470337\n",
      "        - -1.2712340354919434\n",
      "        - -1.2381713390350342\n",
      "        - -1.592871069908142\n",
      "        - -1.0693248510360718\n",
      "        - -1.156333327293396\n",
      "        - -1.4700801372528076\n",
      "        - -1.0576353073120117\n",
      "        - -0.9721832871437073\n",
      "        - -1.275998830795288\n",
      "        - -1.493780493736267\n",
      "        - -0.9561576843261719\n",
      "        - -1.141319751739502\n",
      "        - -1.2613102197647095\n",
      "        - -1.2841116189956665\n",
      "        - -1.4588998556137085\n",
      "        - -0.9150286316871643\n",
      "        - -1.2075363397598267\n",
      "        - -1.9547890424728394\n",
      "        - -1.5695123672485352\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.13333333333333\n",
      "    ram_util_percent: 14.233333333333334\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.05901919735537899\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05907445520787806\n",
      "    mean_inference_ms: 0.710084364488051\n",
      "    mean_raw_obs_processing_ms: 0.14562873573569984\n",
      "  time_since_restore: 1.428520917892456\n",
      "  time_this_iter_s: 1.428520917892456\n",
      "  time_total_s: 1.428520917892456\n",
      "  timers:\n",
      "    learn_throughput: 157.269\n",
      "    learn_time_ms: 203.473\n",
      "    load_throughput: 389036.893\n",
      "    load_time_ms: 0.082\n",
      "  timestamp: 1671815104\n",
      "  timesteps_since_restore: 32\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:09 (running for 00:00:11.82)<br>Memory usage on this node: 4.5/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         4.67432</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\"> 22.1111</td><td style=\"text-align: right;\">                  87</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">           22.1111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 3000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-10\n",
      "  done: false\n",
      "  episode_len_mean: 20.4\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 79.0\n",
      "  episode_reward_mean: 20.4\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 48\n",
      "  episodes_total: 138\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 5.0962934494018555\n",
      "          mean_q: 3.888597011566162\n",
      "          mean_td_error: -0.08276503533124924\n",
      "          min_q: 1.7815723419189453\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.40126991271972656\n",
      "        - -0.35358190536499023\n",
      "        - -0.38391542434692383\n",
      "        - -0.697094202041626\n",
      "        - 0.08998942375183105\n",
      "        - 0.009943485260009766\n",
      "        - 2.5362906455993652\n",
      "        - 0.7815723419189453\n",
      "        - -0.09204721450805664\n",
      "        - -0.0689539909362793\n",
      "        - 2.4388997554779053\n",
      "        - -0.358856201171875\n",
      "        - -0.4499361515045166\n",
      "        - -0.675806999206543\n",
      "        - -0.04701089859008789\n",
      "        - -0.2601752281188965\n",
      "        - -0.7380414009094238\n",
      "        - -0.7380111217498779\n",
      "        - 0.09109735488891602\n",
      "        - -0.1085662841796875\n",
      "        - 0.00237274169921875\n",
      "        - -0.6413712501525879\n",
      "        - -0.02636432647705078\n",
      "        - -1.0632400512695312\n",
      "        - -1.1234660148620605\n",
      "        - 2.2126545906066895\n",
      "        - -0.700350284576416\n",
      "        - -0.6599514484405518\n",
      "        - -0.37361884117126465\n",
      "        - -0.1660914421081543\n",
      "        - -0.8129262924194336\n",
      "        - 0.12934541702270508\n",
      "    num_agent_steps_sampled: 3000\n",
      "    num_agent_steps_trained: 16032\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 52.400000000000006\n",
      "    ram_util_percent: 14.4\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06595607927268117\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06677445829594252\n",
      "    mean_inference_ms: 0.7463353584177986\n",
      "    mean_raw_obs_processing_ms: 0.16058027745364992\n",
      "  time_since_restore: 7.5953638553619385\n",
      "  time_this_iter_s: 2.9210424423217773\n",
      "  time_total_s: 7.5953638553619385\n",
      "  timers:\n",
      "    learn_throughput: 11812.965\n",
      "    learn_time_ms: 2.709\n",
      "    load_throughput: 231929.718\n",
      "    load_time_ms: 0.138\n",
      "  timestamp: 1671815110\n",
      "  timesteps_since_restore: 96\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:15 (running for 00:00:17.50)<br>Memory usage on this node: 4.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         10.3244</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">   22.51</td><td style=\"text-align: right;\">                  95</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             22.51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 5000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-15\n",
      "  done: false\n",
      "  episode_len_mean: 29.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 123.0\n",
      "  episode_reward_mean: 29.9\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 15\n",
      "  episodes_total: 191\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 9.571455001831055\n",
      "          mean_q: 7.340725898742676\n",
      "          mean_td_error: -0.028440535068511963\n",
      "          min_q: 1.5971202850341797\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.05431938171386719\n",
      "        - -0.3390483856201172\n",
      "        - -0.7047390937805176\n",
      "        - 0.056754112243652344\n",
      "        - -0.40581226348876953\n",
      "        - -0.29363536834716797\n",
      "        - 5.498252868652344\n",
      "        - 0.17725849151611328\n",
      "        - 0.06888914108276367\n",
      "        - -0.19385385513305664\n",
      "        - -0.33262157440185547\n",
      "        - -1.4229421615600586\n",
      "        - -0.040438175201416016\n",
      "        - 0.0883932113647461\n",
      "        - -0.1532440185546875\n",
      "        - 0.5971202850341797\n",
      "        - 2.4763989448547363\n",
      "        - -0.06865596771240234\n",
      "        - -0.4494752883911133\n",
      "        - -0.30435991287231445\n",
      "        - -0.8488583564758301\n",
      "        - -0.43603086471557617\n",
      "        - 0.10676288604736328\n",
      "        - -1.591733694076538\n",
      "        - -0.18142223358154297\n",
      "        - -0.2583732604980469\n",
      "        - -0.04416179656982422\n",
      "        - -0.4779777526855469\n",
      "        - -0.7167816162109375\n",
      "        - -0.10061264038085938\n",
      "        - -0.3518338203430176\n",
      "        - -0.20899581909179688\n",
      "    num_agent_steps_sampled: 5000\n",
      "    num_agent_steps_trained: 32032\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.275000000000006\n",
      "    ram_util_percent: 13.9\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0659562899722898\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0666636224780326\n",
      "    mean_inference_ms: 0.738960182257311\n",
      "    mean_raw_obs_processing_ms: 0.15965505977049171\n",
      "  time_since_restore: 12.802182912826538\n",
      "  time_this_iter_s: 2.4777944087982178\n",
      "  time_total_s: 12.802182912826538\n",
      "  timers:\n",
      "    learn_throughput: 13816.511\n",
      "    learn_time_ms: 2.316\n",
      "    load_throughput: 253193.224\n",
      "    load_time_ms: 0.126\n",
      "  timestamp: 1671815115\n",
      "  timesteps_since_restore: 160\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:20 (running for 00:00:23.02)<br>Memory usage on this node: 4.3/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         12.8022</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">    29.9</td><td style=\"text-align: right;\">                 123</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">              29.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 6000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-22\n",
      "  done: false\n",
      "  episode_len_mean: 38.19\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 255.0\n",
      "  episode_reward_mean: 38.19\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 198\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 236.3\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 346.0\n",
      "    episode_reward_mean: 236.3\n",
      "    episode_reward_min: 171.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 292\n",
      "      - 238\n",
      "      - 231\n",
      "      - 186\n",
      "      - 189\n",
      "      - 243\n",
      "      - 346\n",
      "      - 239\n",
      "      - 196\n",
      "      - 266\n",
      "      - 306\n",
      "      - 253\n",
      "      - 207\n",
      "      - 217\n",
      "      - 303\n",
      "      - 192\n",
      "      - 171\n",
      "      - 239\n",
      "      - 189\n",
      "      - 223\n",
      "      episode_reward:\n",
      "      - 292.0\n",
      "      - 238.0\n",
      "      - 231.0\n",
      "      - 186.0\n",
      "      - 189.0\n",
      "      - 243.0\n",
      "      - 346.0\n",
      "      - 239.0\n",
      "      - 196.0\n",
      "      - 266.0\n",
      "      - 306.0\n",
      "      - 253.0\n",
      "      - 207.0\n",
      "      - 217.0\n",
      "      - 303.0\n",
      "      - 192.0\n",
      "      - 171.0\n",
      "      - 239.0\n",
      "      - 189.0\n",
      "      - 223.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06281038641264677\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0632051826325901\n",
      "      mean_inference_ms: 0.6754402931801837\n",
      "      mean_raw_obs_processing_ms: 0.07927452149036229\n",
      "    timesteps_this_iter: 4726\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 5536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 12.402196884155273\n",
      "          mean_q: 9.95598030090332\n",
      "          mean_td_error: 0.6768723130226135\n",
      "          min_q: 4.4173712730407715\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.03205585479736328\n",
      "        - -0.3930683135986328\n",
      "        - -0.02440357208251953\n",
      "        - 0.07915401458740234\n",
      "        - -0.10947799682617188\n",
      "        - -0.046939849853515625\n",
      "        - 0.20501708984375\n",
      "        - -0.565922737121582\n",
      "        - 0.4609107971191406\n",
      "        - 0.10329246520996094\n",
      "        - 3.4173712730407715\n",
      "        - 4.981659889221191\n",
      "        - 0.1525096893310547\n",
      "        - 5.567824363708496\n",
      "        - 0.05104351043701172\n",
      "        - 0.6906719207763672\n",
      "        - -0.4442710876464844\n",
      "        - 0.015423774719238281\n",
      "        - 0.10129356384277344\n",
      "        - -0.06627464294433594\n",
      "        - 8.150131225585938\n",
      "        - 0.1579761505126953\n",
      "        - -0.27446556091308594\n",
      "        - 0.19677448272705078\n",
      "        - 0.09576225280761719\n",
      "        - -0.42731475830078125\n",
      "        - -0.5805678367614746\n",
      "        - -0.22007465362548828\n",
      "        - -0.07122421264648438\n",
      "        - 0.7838735580444336\n",
      "        - -0.06846904754638672\n",
      "        - -0.22624588012695312\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 40032\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 40032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 10\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.766666666666666\n",
      "    ram_util_percent: 13.9\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06568547549601238\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06634894119295094\n",
      "    mean_inference_ms: 0.7356591681033177\n",
      "    mean_raw_obs_processing_ms: 0.1587596757168611\n",
      "  time_since_restore: 19.39868688583374\n",
      "  time_this_iter_s: 6.596503973007202\n",
      "  time_total_s: 19.39868688583374\n",
      "  timers:\n",
      "    learn_throughput: 13933.986\n",
      "    learn_time_ms: 2.297\n",
      "    load_throughput: 254392.964\n",
      "    load_time_ms: 0.126\n",
      "  timestamp: 1671815122\n",
      "  timesteps_since_restore: 192\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 6\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:25 (running for 00:00:28.41)<br>Memory usage on this node: 4.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">         22.1587</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">   45.63</td><td style=\"text-align: right;\">                 255</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             45.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-29\n",
      "  done: false\n",
      "  episode_len_mean: 53.99\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 255.0\n",
      "  episode_reward_mean: 53.99\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 217\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 141.7\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 163.0\n",
      "    episode_reward_mean: 141.7\n",
      "    episode_reward_min: 119.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 148\n",
      "      - 144\n",
      "      - 139\n",
      "      - 148\n",
      "      - 149\n",
      "      - 138\n",
      "      - 132\n",
      "      - 133\n",
      "      - 141\n",
      "      - 146\n",
      "      - 163\n",
      "      - 155\n",
      "      - 149\n",
      "      - 119\n",
      "      - 131\n",
      "      - 146\n",
      "      - 132\n",
      "      - 147\n",
      "      - 135\n",
      "      - 139\n",
      "      episode_reward:\n",
      "      - 148.0\n",
      "      - 144.0\n",
      "      - 139.0\n",
      "      - 148.0\n",
      "      - 149.0\n",
      "      - 138.0\n",
      "      - 132.0\n",
      "      - 133.0\n",
      "      - 141.0\n",
      "      - 146.0\n",
      "      - 163.0\n",
      "      - 155.0\n",
      "      - 149.0\n",
      "      - 119.0\n",
      "      - 131.0\n",
      "      - 146.0\n",
      "      - 132.0\n",
      "      - 147.0\n",
      "      - 135.0\n",
      "      - 139.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.05973606734084087\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05972081187592634\n",
      "      mean_inference_ms: 0.644649824733442\n",
      "      mean_raw_obs_processing_ms: 0.07493451718121794\n",
      "    timesteps_this_iter: 2834\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 7552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 15.80046272277832\n",
      "          mean_q: 12.861526489257812\n",
      "          mean_td_error: 0.5812538862228394\n",
      "          min_q: 6.588455677032471\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 5.588455677032471\n",
      "        - -0.044750213623046875\n",
      "        - 0.17920303344726562\n",
      "        - 0.06503963470458984\n",
      "        - 0.19188976287841797\n",
      "        - -0.9349861145019531\n",
      "        - -0.31826019287109375\n",
      "        - 1.1829032897949219\n",
      "        - -0.8787021636962891\n",
      "        - -0.07241058349609375\n",
      "        - 0.44924259185791016\n",
      "        - -0.12148284912109375\n",
      "        - -0.25193023681640625\n",
      "        - -0.36075496673583984\n",
      "        - -0.2818756103515625\n",
      "        - -0.2775688171386719\n",
      "        - -0.27747058868408203\n",
      "        - 5.912152290344238\n",
      "        - 0.6222763061523438\n",
      "        - -0.48192787170410156\n",
      "        - -0.3445873260498047\n",
      "        - 0.1249094009399414\n",
      "        - -0.17176532745361328\n",
      "        - 0.47032737731933594\n",
      "        - 0.11354351043701172\n",
      "        - -0.12252044677734375\n",
      "        - 0.009485244750976562\n",
      "        - 0.04304790496826172\n",
      "        - -0.24963855743408203\n",
      "        - 0.22383785247802734\n",
      "        - 8.372838020324707\n",
      "        - 0.24160480499267578\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 56032\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 56032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 14\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.34285714285715\n",
      "    ram_util_percent: 13.900000000000002\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0650673281383278\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06561333570724064\n",
      "    mean_inference_ms: 0.7274483784216748\n",
      "    mean_raw_obs_processing_ms: 0.15621296666506101\n",
      "  time_since_restore: 26.94390034675598\n",
      "  time_this_iter_s: 4.785240650177002\n",
      "  time_total_s: 26.94390034675598\n",
      "  timers:\n",
      "    learn_throughput: 13638.904\n",
      "    learn_time_ms: 2.346\n",
      "    load_throughput: 288144.543\n",
      "    load_time_ms: 0.111\n",
      "  timestamp: 1671815129\n",
      "  timesteps_since_restore: 256\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 8\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:31 (running for 00:00:34.23)<br>Memory usage on this node: 4.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">         26.9439</td><td style=\"text-align: right;\">8000</td><td style=\"text-align: right;\">   53.99</td><td style=\"text-align: right;\">                 255</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             53.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:37 (running for 00:00:39.72)<br>Memory usage on this node: 4.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         29.4176</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">   62.05</td><td style=\"text-align: right;\">                 255</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             62.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:42 (running for 00:00:44.75)<br>Memory usage on this node: 4.4/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         29.4176</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">   62.05</td><td style=\"text-align: right;\">                 255</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             62.05</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 10000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-42\n",
      "  done: false\n",
      "  episode_len_mean: 68.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 255.0\n",
      "  episode_reward_mean: 68.11\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 231\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 435.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 435.5\n",
      "    episode_reward_min: 351.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 446\n",
      "      - 456\n",
      "      - 416\n",
      "      - 359\n",
      "      - 470\n",
      "      - 450\n",
      "      - 455\n",
      "      - 462\n",
      "      - 452\n",
      "      - 432\n",
      "      - 396\n",
      "      - 351\n",
      "      - 418\n",
      "      - 500\n",
      "      - 464\n",
      "      - 402\n",
      "      - 409\n",
      "      - 426\n",
      "      - 446\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 446.0\n",
      "      - 456.0\n",
      "      - 416.0\n",
      "      - 359.0\n",
      "      - 470.0\n",
      "      - 450.0\n",
      "      - 455.0\n",
      "      - 462.0\n",
      "      - 452.0\n",
      "      - 432.0\n",
      "      - 396.0\n",
      "      - 351.0\n",
      "      - 418.0\n",
      "      - 500.0\n",
      "      - 464.0\n",
      "      - 402.0\n",
      "      - 409.0\n",
      "      - 426.0\n",
      "      - 446.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06147196506048441\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06159190770468033\n",
      "      mean_inference_ms: 0.6553558994847541\n",
      "      mean_raw_obs_processing_ms: 0.07550778913290021\n",
      "    timesteps_this_iter: 8710\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 9568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 19.060571670532227\n",
      "          mean_q: 15.169143676757812\n",
      "          mean_td_error: 0.31242120265960693\n",
      "          min_q: -0.7693492770195007\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.06279563903808594\n",
      "        - -0.09896087646484375\n",
      "        - -0.23664379119873047\n",
      "        - 0.7778277397155762\n",
      "        - 0.2518463134765625\n",
      "        - 0.250321626663208\n",
      "        - 0.5266799926757812\n",
      "        - 0.3557472229003906\n",
      "        - 0.5528373718261719\n",
      "        - 0.1639423370361328\n",
      "        - 0.3797578811645508\n",
      "        - -0.26218223571777344\n",
      "        - 0.258148193359375\n",
      "        - 0.39623451232910156\n",
      "        - -0.025360107421875\n",
      "        - 3.4306726455688477\n",
      "        - -0.18666458129882812\n",
      "        - 1.5407943725585938\n",
      "        - -0.0325775146484375\n",
      "        - 0.1273822784423828\n",
      "        - 0.17455482482910156\n",
      "        - 0.5180549621582031\n",
      "        - -0.0008373260498046875\n",
      "        - -0.3956737518310547\n",
      "        - -0.15769386291503906\n",
      "        - 0.2790946960449219\n",
      "        - -0.2536039352416992\n",
      "        - 0.2066335678100586\n",
      "        - -0.5255584716796875\n",
      "        - 2.8019464015960693\n",
      "        - -0.5510091781616211\n",
      "        - -0.3310279846191406\n",
      "    num_agent_steps_sampled: 10000\n",
      "    num_agent_steps_trained: 72032\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 72032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 18\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.15714285714286\n",
      "    ram_util_percent: 13.942857142857141\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06451088693082613\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06496152053502008\n",
      "    mean_inference_ms: 0.7202520770670054\n",
      "    mean_raw_obs_processing_ms: 0.15391760586340253\n",
      "  time_since_restore: 39.56250262260437\n",
      "  time_this_iter_s: 10.144917726516724\n",
      "  time_total_s: 39.56250262260437\n",
      "  timers:\n",
      "    learn_throughput: 12282.003\n",
      "    learn_time_ms: 2.605\n",
      "    load_throughput: 225765.733\n",
      "    load_time_ms: 0.142\n",
      "  timestamp: 1671815142\n",
      "  timesteps_since_restore: 320\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 10\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:48 (running for 00:00:50.53)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         42.1821</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">   79.46</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             79.46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-05-50\n",
      "  done: false\n",
      "  episode_len_mean: 86.71\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 86.71\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 250\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 179.9\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 192.0\n",
      "    episode_reward_mean: 179.9\n",
      "    episode_reward_min: 167.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 177\n",
      "      - 186\n",
      "      - 176\n",
      "      - 181\n",
      "      - 182\n",
      "      - 174\n",
      "      - 185\n",
      "      - 185\n",
      "      - 168\n",
      "      - 189\n",
      "      - 175\n",
      "      - 183\n",
      "      - 167\n",
      "      - 192\n",
      "      - 187\n",
      "      - 184\n",
      "      - 180\n",
      "      - 170\n",
      "      - 180\n",
      "      - 177\n",
      "      episode_reward:\n",
      "      - 177.0\n",
      "      - 186.0\n",
      "      - 176.0\n",
      "      - 181.0\n",
      "      - 182.0\n",
      "      - 174.0\n",
      "      - 185.0\n",
      "      - 185.0\n",
      "      - 168.0\n",
      "      - 189.0\n",
      "      - 175.0\n",
      "      - 183.0\n",
      "      - 167.0\n",
      "      - 192.0\n",
      "      - 187.0\n",
      "      - 184.0\n",
      "      - 180.0\n",
      "      - 170.0\n",
      "      - 180.0\n",
      "      - 177.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0616871298522784\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06183026773576441\n",
      "      mean_inference_ms: 0.6573646916359037\n",
      "      mean_raw_obs_processing_ms: 0.07576926268751097\n",
      "    timesteps_this_iter: 3598\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 11584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 22.728239059448242\n",
      "          mean_q: 16.944353103637695\n",
      "          mean_td_error: 0.6396517753601074\n",
      "          min_q: 3.0769882202148438\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.7396163940429688\n",
      "        - -0.34760093688964844\n",
      "        - -0.4523487091064453\n",
      "        - -0.16733932495117188\n",
      "        - -2.016995429992676\n",
      "        - -0.18007278442382812\n",
      "        - 15.240455627441406\n",
      "        - -1.3240642547607422\n",
      "        - 0.18771934509277344\n",
      "        - 0.23554039001464844\n",
      "        - 4.280830383300781\n",
      "        - -1.656515121459961\n",
      "        - 0.2590370178222656\n",
      "        - -0.1490325927734375\n",
      "        - -0.6412067413330078\n",
      "        - -0.49979209899902344\n",
      "        - -2.229816436767578\n",
      "        - -0.060302734375\n",
      "        - -0.7639484405517578\n",
      "        - 0.11288070678710938\n",
      "        - -0.09438896179199219\n",
      "        - -0.29366302490234375\n",
      "        - 2.9578819274902344\n",
      "        - -0.010440826416015625\n",
      "        - 8.000492095947266\n",
      "        - 0.3431053161621094\n",
      "        - 0.5350341796875\n",
      "        - 0.019906997680664062\n",
      "        - 0.06150245666503906\n",
      "        - 0.3209552764892578\n",
      "        - -0.352813720703125\n",
      "        - -0.10652732849121094\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 88032\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 88032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 22\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.8875\n",
      "    ram_util_percent: 14.537500000000001\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06392791575202467\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06426571442897094\n",
      "    mean_inference_ms: 0.7125593406333018\n",
      "    mean_raw_obs_processing_ms: 0.15112686524148852\n",
      "  time_since_restore: 48.002426624298096\n",
      "  time_this_iter_s: 5.820372104644775\n",
      "  time_total_s: 48.002426624298096\n",
      "  timers:\n",
      "    learn_throughput: 13789.682\n",
      "    learn_time_ms: 2.321\n",
      "    load_throughput: 288144.543\n",
      "    load_time_ms: 0.111\n",
      "  timestamp: 1671815150\n",
      "  timesteps_since_restore: 384\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 12\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:53 (running for 00:00:56.14)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         50.7288</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">   92.68</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             92.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:05:58 (running for 00:01:01.15)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         50.7288</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">   92.68</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             92.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:03 (running for 00:01:06.18)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         50.7288</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">   92.68</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             92.68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 14000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-06-04\n",
      "  done: false\n",
      "  episode_len_mean: 102.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 102.37\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 254\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.05945267169210977\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05928804728183399\n",
      "      mean_inference_ms: 0.6367695134731409\n",
      "      mean_raw_obs_processing_ms: 0.07262263237214\n",
      "    timesteps_this_iter: 10000\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 13600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 25.544960021972656\n",
      "          mean_q: 22.34271240234375\n",
      "          mean_td_error: 0.25331032276153564\n",
      "          min_q: 5.70624303817749\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.39226722717285156\n",
      "        - 0.2907867431640625\n",
      "        - -0.19804763793945312\n",
      "        - 0.39064979553222656\n",
      "        - 0.071929931640625\n",
      "        - -0.25378990173339844\n",
      "        - -0.2524394989013672\n",
      "        - -0.4470500946044922\n",
      "        - -0.5290775299072266\n",
      "        - 0.37662506103515625\n",
      "        - -0.06186676025390625\n",
      "        - -0.18386077880859375\n",
      "        - 1.1094551086425781\n",
      "        - -0.16094970703125\n",
      "        - 4.70624303817749\n",
      "        - -0.042449951171875\n",
      "        - -0.3629150390625\n",
      "        - 0.5081386566162109\n",
      "        - 0.8526554107666016\n",
      "        - 1.5429248809814453\n",
      "        - -0.09686660766601562\n",
      "        - 1.9667444229125977\n",
      "        - -0.2591133117675781\n",
      "        - 0.4520378112792969\n",
      "        - -0.3957653045654297\n",
      "        - 0.2637977600097656\n",
      "        - -1.913125991821289\n",
      "        - 0.6670494079589844\n",
      "        - -0.19500350952148438\n",
      "        - 0.1576690673828125\n",
      "        - -0.09650421142578125\n",
      "        - -0.19421768188476562\n",
      "    num_agent_steps_sampled: 14000\n",
      "    num_agent_steps_trained: 104032\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 104032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 26\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.08666666666667\n",
      "    ram_util_percent: 14.599999999999998\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06384936110637185\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06417085236558837\n",
      "    mean_inference_ms: 0.7114018904236739\n",
      "    mean_raw_obs_processing_ms: 0.15060383031968694\n",
      "  time_since_restore: 61.33223557472229\n",
      "  time_this_iter_s: 10.603469133377075\n",
      "  time_total_s: 61.33223557472229\n",
      "  timers:\n",
      "    learn_throughput: 14186.271\n",
      "    learn_time_ms: 2.256\n",
      "    load_throughput: 303179.869\n",
      "    load_time_ms: 0.106\n",
      "  timestamp: 1671815164\n",
      "  timesteps_since_restore: 448\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 14\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:09 (running for 00:01:11.69)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         64.2269</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">  112.16</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">            112.16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-06-13\n",
      "  done: false\n",
      "  episode_len_mean: 123.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 123.9\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 260\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 228.95\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 288.0\n",
      "    episode_reward_mean: 228.95\n",
      "    episode_reward_min: 139.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 213\n",
      "      - 212\n",
      "      - 232\n",
      "      - 232\n",
      "      - 224\n",
      "      - 144\n",
      "      - 264\n",
      "      - 230\n",
      "      - 238\n",
      "      - 222\n",
      "      - 227\n",
      "      - 248\n",
      "      - 224\n",
      "      - 266\n",
      "      - 288\n",
      "      - 235\n",
      "      - 254\n",
      "      - 256\n",
      "      - 139\n",
      "      - 231\n",
      "      episode_reward:\n",
      "      - 213.0\n",
      "      - 212.0\n",
      "      - 232.0\n",
      "      - 232.0\n",
      "      - 224.0\n",
      "      - 144.0\n",
      "      - 264.0\n",
      "      - 230.0\n",
      "      - 238.0\n",
      "      - 222.0\n",
      "      - 227.0\n",
      "      - 248.0\n",
      "      - 224.0\n",
      "      - 266.0\n",
      "      - 288.0\n",
      "      - 235.0\n",
      "      - 254.0\n",
      "      - 256.0\n",
      "      - 139.0\n",
      "      - 231.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.05904571979998998\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05886496000956285\n",
      "      mean_inference_ms: 0.6328051305991541\n",
      "      mean_raw_obs_processing_ms: 0.07214086025714331\n",
      "    timesteps_this_iter: 4579\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 15616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 29.476625442504883\n",
      "          mean_q: 25.110992431640625\n",
      "          mean_td_error: 0.25696438550949097\n",
      "          min_q: -2.207603931427002\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.32314109802246094\n",
      "        - 0.4158964157104492\n",
      "        - 0.1577777862548828\n",
      "        - -0.053192138671875\n",
      "        - -0.3242912292480469\n",
      "        - -0.07735633850097656\n",
      "        - 0.08830070495605469\n",
      "        - -0.46890830993652344\n",
      "        - -0.08477020263671875\n",
      "        - 0.00283050537109375\n",
      "        - -2.069032669067383\n",
      "        - -0.2439727783203125\n",
      "        - -0.2127094268798828\n",
      "        - 0.4530353546142578\n",
      "        - -0.23205184936523438\n",
      "        - -3.207603931427002\n",
      "        - -0.6604995727539062\n",
      "        - -1.8694515228271484\n",
      "        - -0.8425502777099609\n",
      "        - -0.5107269287109375\n",
      "        - 0.6798915863037109\n",
      "        - 20.031230926513672\n",
      "        - 0.09064674377441406\n",
      "        - -0.05457878112792969\n",
      "        - -1.3521480560302734\n",
      "        - 0.09512710571289062\n",
      "        - -0.48136138916015625\n",
      "        - 0.2758827209472656\n",
      "        - -0.21184921264648438\n",
      "        - 0.2263813018798828\n",
      "        - -1.3429527282714844\n",
      "        - -0.3172760009765625\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 120032\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 120032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 30\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.27777777777778\n",
      "    ram_util_percent: 14.600000000000001\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06378360152337614\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06409038278099534\n",
      "    mean_inference_ms: 0.710098127293171\n",
      "    mean_raw_obs_processing_ms: 0.1498678845422432\n",
      "  time_since_restore: 70.62743592262268\n",
      "  time_this_iter_s: 6.400583267211914\n",
      "  time_total_s: 70.62743592262268\n",
      "  timers:\n",
      "    learn_throughput: 11842.776\n",
      "    learn_time_ms: 2.702\n",
      "    load_throughput: 216515.128\n",
      "    load_time_ms: 0.148\n",
      "  timestamp: 1671815173\n",
      "  timesteps_since_restore: 512\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 16\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:14 (running for 00:01:17.11)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         70.6274</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">   123.9</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             123.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 18000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-06-19\n",
      "  done: false\n",
      "  episode_len_mean: 139.7\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 139.7\n",
      "  episode_reward_min: 18.0\n",
      "  episodes_this_iter: 13\n",
      "  episodes_total: 279\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 41.9\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 48.0\n",
      "    episode_reward_mean: 41.9\n",
      "    episode_reward_min: 36.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 42\n",
      "      - 36\n",
      "      - 43\n",
      "      - 44\n",
      "      - 42\n",
      "      - 43\n",
      "      - 46\n",
      "      - 36\n",
      "      - 48\n",
      "      - 39\n",
      "      - 46\n",
      "      - 36\n",
      "      - 40\n",
      "      - 45\n",
      "      - 44\n",
      "      - 41\n",
      "      - 46\n",
      "      - 38\n",
      "      - 41\n",
      "      - 42\n",
      "      episode_reward:\n",
      "      - 42.0\n",
      "      - 36.0\n",
      "      - 43.0\n",
      "      - 44.0\n",
      "      - 42.0\n",
      "      - 43.0\n",
      "      - 46.0\n",
      "      - 36.0\n",
      "      - 48.0\n",
      "      - 39.0\n",
      "      - 46.0\n",
      "      - 36.0\n",
      "      - 40.0\n",
      "      - 45.0\n",
      "      - 44.0\n",
      "      - 41.0\n",
      "      - 46.0\n",
      "      - 38.0\n",
      "      - 41.0\n",
      "      - 42.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.05905059728254921\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05887502044817698\n",
      "      mean_inference_ms: 0.6328251239297187\n",
      "      mean_raw_obs_processing_ms: 0.07230229102776443\n",
      "    timesteps_this_iter: 838\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 17632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 33.84225082397461\n",
      "          mean_q: 29.489046096801758\n",
      "          mean_td_error: 0.729319155216217\n",
      "          min_q: 21.27861976623535\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.4395484924316406\n",
      "        - -0.5856723785400391\n",
      "        - 1.8734989166259766\n",
      "        - -1.2450885772705078\n",
      "        - -0.9610538482666016\n",
      "        - -0.23960494995117188\n",
      "        - -1.1197738647460938\n",
      "        - 1.8822078704833984\n",
      "        - -0.29056739807128906\n",
      "        - 0.3938026428222656\n",
      "        - -0.050624847412109375\n",
      "        - 0.3955650329589844\n",
      "        - 0.4749031066894531\n",
      "        - -1.6197853088378906\n",
      "        - -0.06540298461914062\n",
      "        - 0.05376434326171875\n",
      "        - 0.6338939666748047\n",
      "        - 0.5220985412597656\n",
      "        - 0.5288848876953125\n",
      "        - -0.7839794158935547\n",
      "        - -0.49707603454589844\n",
      "        - -0.3026084899902344\n",
      "        - 0.40998268127441406\n",
      "        - 0.04668426513671875\n",
      "        - 0.20141983032226562\n",
      "        - -0.34737586975097656\n",
      "        - 21.62624168395996\n",
      "        - -0.40642547607421875\n",
      "        - -0.4128532409667969\n",
      "        - 0.5019588470458984\n",
      "        - 0.5365371704101562\n",
      "        - 2.6242103576660156\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 136032\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 136032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 34\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 41.58\n",
      "    ram_util_percent: 14.62\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06353413915778716\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06378569992469453\n",
      "    mean_inference_ms: 0.7055246110484432\n",
      "    mean_raw_obs_processing_ms: 0.14743106560604324\n",
      "  time_since_restore: 76.3102548122406\n",
      "  time_this_iter_s: 3.212022066116333\n",
      "  time_total_s: 76.3102548122406\n",
      "  timers:\n",
      "    learn_throughput: 12783.128\n",
      "    learn_time_ms: 2.503\n",
      "    load_throughput: 286056.539\n",
      "    load_time_ms: 0.112\n",
      "  timestamp: 1671815179\n",
      "  timesteps_since_restore: 576\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 18\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:20 (running for 00:01:22.85)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         76.3103</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">   139.7</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  18</td><td style=\"text-align: right;\">             139.7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:25 (running for 00:01:27.87)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         79.3179</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">  142.02</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  23</td><td style=\"text-align: right;\">            142.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-06-27\n",
      "  done: false\n",
      "  episode_len_mean: 140.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 140.3\n",
      "  episode_reward_min: 23.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 298\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 139.6\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 205.0\n",
      "    episode_reward_mean: 139.6\n",
      "    episode_reward_min: 116.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 116\n",
      "      - 119\n",
      "      - 137\n",
      "      - 117\n",
      "      - 180\n",
      "      - 119\n",
      "      - 131\n",
      "      - 123\n",
      "      - 165\n",
      "      - 130\n",
      "      - 126\n",
      "      - 129\n",
      "      - 128\n",
      "      - 148\n",
      "      - 128\n",
      "      - 136\n",
      "      - 121\n",
      "      - 131\n",
      "      - 205\n",
      "      - 203\n",
      "      episode_reward:\n",
      "      - 116.0\n",
      "      - 119.0\n",
      "      - 137.0\n",
      "      - 117.0\n",
      "      - 180.0\n",
      "      - 119.0\n",
      "      - 131.0\n",
      "      - 123.0\n",
      "      - 165.0\n",
      "      - 130.0\n",
      "      - 126.0\n",
      "      - 129.0\n",
      "      - 128.0\n",
      "      - 148.0\n",
      "      - 128.0\n",
      "      - 136.0\n",
      "      - 121.0\n",
      "      - 131.0\n",
      "      - 205.0\n",
      "      - 203.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.058814845351084354\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.058609774449765305\n",
      "      mean_inference_ms: 0.6304301052860403\n",
      "      mean_raw_obs_processing_ms: 0.07207765344206617\n",
      "    timesteps_this_iter: 2792\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 19648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 36.292869567871094\n",
      "          mean_q: 27.47606086730957\n",
      "          mean_td_error: 3.453352928161621\n",
      "          min_q: -0.1886124610900879\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.15967178344726562\n",
      "        - 17.519447326660156\n",
      "        - 0.10947036743164062\n",
      "        - 1.3782858848571777\n",
      "        - -0.44489288330078125\n",
      "        - 0.56304931640625\n",
      "        - -0.37708282470703125\n",
      "        - 0.0032501220703125\n",
      "        - -0.3377571105957031\n",
      "        - 0.05071258544921875\n",
      "        - 23.36280059814453\n",
      "        - -0.11135482788085938\n",
      "        - 25.944971084594727\n",
      "        - 1.9939422607421875\n",
      "        - 3.1359076499938965\n",
      "        - 3.4148521423339844\n",
      "        - -0.5995368957519531\n",
      "        - -0.7633800506591797\n",
      "        - -0.7601661682128906\n",
      "        - -0.025054931640625\n",
      "        - 22.70909309387207\n",
      "        - -0.6046409606933594\n",
      "        - 2.608051300048828\n",
      "        - 0.4048271179199219\n",
      "        - 10.224102020263672\n",
      "        - 0.07767486572265625\n",
      "        - 1.2521018981933594\n",
      "        - 0.1584320068359375\n",
      "        - 0.6156387329101562\n",
      "        - 0.036899566650390625\n",
      "        - -0.20701980590820312\n",
      "        - -0.6656608581542969\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 152032\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 152032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 38\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.457142857142856\n",
      "    ram_util_percent: 14.700000000000001\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06367111844159204\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0639165845245327\n",
      "    mean_inference_ms: 0.7051937233443047\n",
      "    mean_raw_obs_processing_ms: 0.14610550517920246\n",
      "  time_since_restore: 84.36861371994019\n",
      "  time_this_iter_s: 5.050695896148682\n",
      "  time_total_s: 84.36861371994019\n",
      "  timers:\n",
      "    learn_throughput: 12390.167\n",
      "    learn_time_ms: 2.583\n",
      "    load_throughput: 237217.618\n",
      "    load_time_ms: 0.135\n",
      "  timestamp: 1671815187\n",
      "  timesteps_since_restore: 640\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 20\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:30 (running for 00:01:33.45)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         86.8557</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">  141.84</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  23</td><td style=\"text-align: right;\">            141.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:06:36 (running for 00:01:38.48)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.94 GiB heap, 0.0/8.47 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_ec84f_00000</td><td>RUNNING </td><td>192.168.0.98:72303</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         86.8557</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">  141.84</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  23</td><td style=\"text-align: right;\">            141.84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_ec84f_00000:\n",
      "  agent_timesteps_total: 22000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-06-38\n",
      "  done: false\n",
      "  episode_len_mean: 145.3\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 145.3\n",
      "  episode_reward_min: 23.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 313\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 327.9\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 387.0\n",
      "    episode_reward_mean: 327.9\n",
      "    episode_reward_min: 280.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 280\n",
      "      - 336\n",
      "      - 336\n",
      "      - 387\n",
      "      - 364\n",
      "      - 317\n",
      "      - 377\n",
      "      - 296\n",
      "      - 347\n",
      "      - 314\n",
      "      - 328\n",
      "      - 302\n",
      "      - 352\n",
      "      - 307\n",
      "      - 332\n",
      "      - 288\n",
      "      - 317\n",
      "      - 362\n",
      "      - 303\n",
      "      - 313\n",
      "      episode_reward:\n",
      "      - 280.0\n",
      "      - 336.0\n",
      "      - 336.0\n",
      "      - 387.0\n",
      "      - 364.0\n",
      "      - 317.0\n",
      "      - 377.0\n",
      "      - 296.0\n",
      "      - 347.0\n",
      "      - 314.0\n",
      "      - 328.0\n",
      "      - 302.0\n",
      "      - 352.0\n",
      "      - 307.0\n",
      "      - 332.0\n",
      "      - 288.0\n",
      "      - 317.0\n",
      "      - 362.0\n",
      "      - 303.0\n",
      "      - 313.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.05931125693977898\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05910634317962142\n",
      "      mean_inference_ms: 0.6341464164103348\n",
      "      mean_raw_obs_processing_ms: 0.07259659155300771\n",
      "    timesteps_this_iter: 6558\n",
      "  experiment_id: b0a5e9ceca9a44a597da6b81a80f9ee6\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 21664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 37.97380447387695\n",
      "          mean_q: 33.11193084716797\n",
      "          mean_td_error: 1.1748348474502563\n",
      "          min_q: 19.826030731201172\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.41144752502441406\n",
      "        - -0.29446983337402344\n",
      "        - -0.3495750427246094\n",
      "        - -0.44632720947265625\n",
      "        - 28.150476455688477\n",
      "        - -0.5949554443359375\n",
      "        - -0.12916946411132812\n",
      "        - -0.0602874755859375\n",
      "        - -1.0481300354003906\n",
      "        - -3.3919639587402344\n",
      "        - -0.3282737731933594\n",
      "        - -0.70660400390625\n",
      "        - -0.3968009948730469\n",
      "        - -0.8162345886230469\n",
      "        - 0.034580230712890625\n",
      "        - -0.4267406463623047\n",
      "        - -0.6182479858398438\n",
      "        - -0.7316932678222656\n",
      "        - -0.3052787780761719\n",
      "        - -0.9413681030273438\n",
      "        - -0.6040573120117188\n",
      "        - 29.705659866333008\n",
      "        - -0.9444427490234375\n",
      "        - -0.6621017456054688\n",
      "        - 0.3167457580566406\n",
      "        - -1.0423927307128906\n",
      "        - -0.009979248046875\n",
      "        - -1.7392959594726562\n",
      "        - -0.563720703125\n",
      "        - -0.1530609130859375\n",
      "        - -3.5320301055908203\n",
      "        - 0.6359024047851562\n",
      "    num_agent_steps_sampled: 22000\n",
      "    num_agent_steps_trained: 168032\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 168032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 42\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.16363636363637\n",
      "    ram_util_percent: 14.699999999999996\n",
      "  pid: 72303\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06373533599444778\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06397923370991704\n",
      "    mean_inference_ms: 0.704980113414031\n",
      "    mean_raw_obs_processing_ms: 0.14540321621300248\n",
      "  time_since_restore: 94.98919463157654\n",
      "  time_this_iter_s: 8.133480310440063\n",
      "  time_total_s: 94.98919463157654\n",
      "  timers:\n",
      "    learn_throughput: 14231.699\n",
      "    learn_time_ms: 2.249\n",
      "    load_throughput: 296876.196\n",
      "    load_time_ms: 0.108\n",
      "  timestamp: 1671815198\n",
      "  timesteps_since_restore: 704\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 22\n",
      "  trial_id: ec84f_00000\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "tune.run(\"DQN\",\n",
    "         config={\"env\": \"CartPole-v1\",\n",
    "                 \"evaluation_interval\": 2, \n",
    "                 \"evaluation_num_episodes\": 20,\n",
    "                 },\n",
    "         local_dir=\"cartpole_v1\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497cc95-37e1-4c5f-9c60-b43c31d6f2bf",
   "metadata": {},
   "source": [
    "## Tensorboard can autodetect different experiments stored under the same results dir\n",
    "\n",
    "- Use `tensorboard logdir=cartpole_v1`\n",
    "\n",
    "```\n",
    "cartpole_v1/\n",
    " DQN\n",
    "  basic-variant-state-2021-06-11_11-46-36.json\n",
    "  DQN_CartPole-v1_e97f1_00000_0_2021-06-11_11-46-36\n",
    "   events.out.tfevents.1623404796.devbox-x299\n",
    "   params.json\n",
    "   params.pkl\n",
    "   progress.csv\n",
    "   result.json\n",
    "  experiment_state-2021-06-11_11-46-36.json\n",
    " PPO\n",
    "     basic-variant-state-2021-06-11_11-46-26.json\n",
    "     experiment_state-2021-06-11_11-46-26.json\n",
    "     PPO_CartPole-v1_e3e63_00000_0_2021-06-11_11-46-26\n",
    "         events.out.tfevents.1623404786.devbox-x299\n",
    "         params.json\n",
    "         params.pkl\n",
    "         progress.csv\n",
    "         result.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
