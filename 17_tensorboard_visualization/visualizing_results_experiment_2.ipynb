{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa994ae-ee9b-4e46-afc3-06c3ab38feec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run a second experiment using the DQN algorithm\n",
    " \n",
    "- Allowed algorithm names can be found [here](https://docs.ray.io/en/master/rllib-algorithms.html)\n",
    "- To visualize both experiments together, use the same results directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ceed762-e676-480c-814f-0c99b2d5c979",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.0.98',\n",
       " 'raylet_ip_address': '192.168.0.98',\n",
       " 'redis_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2022-12-23_17-16-48_268795_156880/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2022-12-23_17-16-48_268795_156880/sockets/raylet',\n",
       " 'webui_url': None,\n",
       " 'session_dir': '/tmp/ray/session_2022-12-23_17-16-48_268795_156880',\n",
       " 'metrics_export_port': 39553,\n",
       " 'gcs_address': '192.168.0.98:60148',\n",
       " 'address': '192.168.0.98:60148',\n",
       " 'node_id': '4247b4b7fd8c3b1b38daaeb33d2f063d423edab0d0a788924bb0abf7'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1961d539-2395-44c0-9bcd-d4586a229024",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQNTrainer pid=157047)\u001b[0m 2022-12-23 17:16:55,718\tINFO trainer.py:2140 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=157047)\u001b[0m 2022-12-23 17:16:55,719\tWARNING deprecation.py:45 -- DeprecationWarning: `evaluation_num_episodes` has been deprecated. Use ``evaluation_duration` and `evaluation_duration_unit=episodes`` instead. This will raise an error in the future!\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=157047)\u001b[0m 2022-12-23 17:16:55,719\tINFO simple_q.py:154 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=157047)\u001b[0m 2022-12-23 17:16:55,719\tINFO trainer.py:779 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(DQNTrainer pid=157047)\u001b[0m 2022-12-23 17:16:57,303\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:16:58 (running for 00:00:05.63)<br>Memory usage on this node: 4.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(DQNTrainer pid=157047)\u001b[0m 2022-12-23 17:16:58,636\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:16:59 (running for 00:00:06.63)<br>Memory usage on this node: 4.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 1000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-00\n",
      "  done: false\n",
      "  episode_len_mean: 25.86842105263158\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 72.0\n",
      "  episode_reward_mean: 25.86842105263158\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 38\n",
      "  episodes_total: 38\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 1000\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 0.22878295183181763\n",
      "          mean_q: -0.3380986750125885\n",
      "          mean_td_error: -1.4504934549331665\n",
      "          min_q: -1.1020764112472534\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.7712170481681824\n",
      "        - -1.409583568572998\n",
      "        - -2.254580497741699\n",
      "        - -1.2396280765533447\n",
      "        - -1.7471739053726196\n",
      "        - -1.3433349132537842\n",
      "        - -1.5487818717956543\n",
      "        - -1.5548489093780518\n",
      "        - -1.4742133617401123\n",
      "        - -1.9743038415908813\n",
      "        - -2.186458110809326\n",
      "        - -2.172408103942871\n",
      "        - -2.1870765686035156\n",
      "        - -1.0911253690719604\n",
      "        - -1.2786219120025635\n",
      "        - -1.4449245929718018\n",
      "        - -1.1607698202133179\n",
      "        - -0.9451993107795715\n",
      "        - -0.7997677326202393\n",
      "        - -1.2378419637680054\n",
      "        - -1.9908382892608643\n",
      "        - -1.511976957321167\n",
      "        - -1.1693670749664307\n",
      "        - -1.4128423929214478\n",
      "        - -2.1729302406311035\n",
      "        - -1.307732343673706\n",
      "        - -1.0836385488510132\n",
      "        - -1.3454866409301758\n",
      "        - -1.22003173828125\n",
      "        - -1.0201143026351929\n",
      "        - -1.378758430480957\n",
      "        - -0.9802140593528748\n",
      "    num_agent_steps_sampled: 1000\n",
      "    num_agent_steps_trained: 32\n",
      "    num_steps_sampled: 1000\n",
      "    num_steps_trained: 32\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 1\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.13333333333333\n",
      "    ram_util_percent: 15.433333333333332\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.061460784622482\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.05988188675948076\n",
      "    mean_inference_ms: 0.7174653368634542\n",
      "    mean_raw_obs_processing_ms: 0.14572900968355376\n",
      "  time_since_restore: 1.4558029174804688\n",
      "  time_this_iter_s: 1.4558029174804688\n",
      "  time_total_s: 1.4558029174804688\n",
      "  timers:\n",
      "    learn_throughput: 152.721\n",
      "    learn_time_ms: 209.533\n",
      "    load_throughput: 208412.621\n",
      "    load_time_ms: 0.154\n",
      "  timestamp: 1671815820\n",
      "  timesteps_since_restore: 32\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 1000\n",
      "  training_iteration: 1\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:05 (running for 00:00:12.35)<br>Memory usage on this node: 4.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">         4.64978</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">  22.382</td><td style=\"text-align: right;\">                  72</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">            22.382</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 3000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-06\n",
      "  done: false\n",
      "  episode_len_mean: 21.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 72.0\n",
      "  episode_reward_mean: 21.37\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 41\n",
      "  episodes_total: 130\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 2512\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 4.781843185424805\n",
      "          mean_q: 3.685673713684082\n",
      "          mean_td_error: 0.4327484369277954\n",
      "          min_q: 1.8747302293777466\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.6359782218933105\n",
      "        - 1.1662092208862305\n",
      "        - -0.15033340454101562\n",
      "        - 0.7634696960449219\n",
      "        - 0.8747302293777466\n",
      "        - -0.23929715156555176\n",
      "        - -0.07180666923522949\n",
      "        - 0.31861114501953125\n",
      "        - 2.4672179222106934\n",
      "        - -0.2738189697265625\n",
      "        - 2.187234401702881\n",
      "        - -0.09321022033691406\n",
      "        - -0.3050422668457031\n",
      "        - -0.14607954025268555\n",
      "        - 1.8010997772216797\n",
      "        - 2.4672179222106934\n",
      "        - 0.09164953231811523\n",
      "        - 0.00561976432800293\n",
      "        - -0.24164175987243652\n",
      "        - -0.2751021385192871\n",
      "        - -0.4733729362487793\n",
      "        - -0.06688976287841797\n",
      "        - -0.305828332901001\n",
      "        - 0.7961771488189697\n",
      "        - 0.2102985382080078\n",
      "        - -0.21796560287475586\n",
      "        - 0.036457061767578125\n",
      "        - 0.4112992286682129\n",
      "        - 1.662674903869629\n",
      "        - 0.08608365058898926\n",
      "        - -0.4078054428100586\n",
      "        - 1.13411545753479\n",
      "    num_agent_steps_sampled: 3000\n",
      "    num_agent_steps_trained: 16032\n",
      "    num_steps_sampled: 3000\n",
      "    num_steps_trained: 16032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 4\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.925\n",
      "    ram_util_percent: 15.5\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06680648628614909\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06595941184113877\n",
      "    mean_inference_ms: 0.7405312878412369\n",
      "    mean_raw_obs_processing_ms: 0.15702748332337596\n",
      "  time_since_restore: 7.534679412841797\n",
      "  time_this_iter_s: 2.8848979473114014\n",
      "  time_total_s: 7.534679412841797\n",
      "  timers:\n",
      "    learn_throughput: 11954.693\n",
      "    learn_time_ms: 2.677\n",
      "    load_throughput: 230021.813\n",
      "    load_time_ms: 0.139\n",
      "  timestamp: 1671815826\n",
      "  timesteps_since_restore: 96\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 3000\n",
      "  training_iteration: 3\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:10 (running for 00:00:17.86)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">         12.1367</td><td style=\"text-align: right;\">4000</td><td style=\"text-align: right;\">   26.76</td><td style=\"text-align: right;\">                 192</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             26.76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 5000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-13\n",
      "  done: false\n",
      "  episode_len_mean: 34.62\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 192.0\n",
      "  episode_reward_mean: 34.62\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 12\n",
      "  episodes_total: 164\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 4528\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 9.505013465881348\n",
      "          mean_q: 7.707068920135498\n",
      "          mean_td_error: 0.10319142043590546\n",
      "          min_q: 2.6788997650146484\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.9681587219238281\n",
      "        - 0.834322452545166\n",
      "        - -0.2755918502807617\n",
      "        - 0.047760963439941406\n",
      "        - -0.2767753601074219\n",
      "        - -0.10035896301269531\n",
      "        - -0.21449565887451172\n",
      "        - -0.4695320129394531\n",
      "        - 0.5364761352539062\n",
      "        - -0.18684005737304688\n",
      "        - 0.4648408889770508\n",
      "        - 1.6788997650146484\n",
      "        - 0.21224403381347656\n",
      "        - -0.0715169906616211\n",
      "        - -0.27213001251220703\n",
      "        - -0.1366443634033203\n",
      "        - -0.44146251678466797\n",
      "        - 0.2792692184448242\n",
      "        - -0.0073223114013671875\n",
      "        - -0.5466785430908203\n",
      "        - -0.46119117736816406\n",
      "        - -0.20836734771728516\n",
      "        - 0.5555200576782227\n",
      "        - 0.6716909408569336\n",
      "        - -0.9590797424316406\n",
      "        - -0.17317581176757812\n",
      "        - 4.055122375488281\n",
      "        - 0.5171298980712891\n",
      "        - -0.01764965057373047\n",
      "        - -0.22032928466796875\n",
      "        - -0.6540460586547852\n",
      "        - 0.11019515991210938\n",
      "    num_agent_steps_sampled: 5000\n",
      "    num_agent_steps_trained: 32032\n",
      "    num_steps_sampled: 5000\n",
      "    num_steps_trained: 32032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 8\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.175000000000004\n",
      "    ram_util_percent: 15.5\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0672270242908979\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06650016635807296\n",
      "    mean_inference_ms: 0.7376196005641157\n",
      "    mean_raw_obs_processing_ms: 0.1567361761587367\n",
      "  time_since_restore: 14.769567251205444\n",
      "  time_this_iter_s: 2.6328327655792236\n",
      "  time_total_s: 14.769567251205444\n",
      "  timers:\n",
      "    learn_throughput: 12000.763\n",
      "    learn_time_ms: 2.666\n",
      "    load_throughput: 234318.659\n",
      "    load_time_ms: 0.137\n",
      "  timestamp: 1671815833\n",
      "  timesteps_since_restore: 160\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 5000\n",
      "  training_iteration: 5\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:16 (running for 00:00:23.56)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         14.7696</td><td style=\"text-align: right;\">5000</td><td style=\"text-align: right;\">   34.62</td><td style=\"text-align: right;\">                 192</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             34.62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 6000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-19\n",
      "  done: false\n",
      "  episode_len_mean: 42.9\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 192.0\n",
      "  episode_reward_mean: 42.9\n",
      "  episode_reward_min: 9.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 173\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 206.1\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 206.1\n",
      "    episode_reward_min: 115.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 381\n",
      "      - 122\n",
      "      - 189\n",
      "      - 157\n",
      "      - 147\n",
      "      - 180\n",
      "      - 210\n",
      "      - 187\n",
      "      - 155\n",
      "      - 115\n",
      "      - 354\n",
      "      - 211\n",
      "      - 500\n",
      "      - 274\n",
      "      - 126\n",
      "      - 209\n",
      "      - 137\n",
      "      - 124\n",
      "      - 228\n",
      "      - 116\n",
      "      episode_reward:\n",
      "      - 381.0\n",
      "      - 122.0\n",
      "      - 189.0\n",
      "      - 157.0\n",
      "      - 147.0\n",
      "      - 180.0\n",
      "      - 210.0\n",
      "      - 187.0\n",
      "      - 155.0\n",
      "      - 115.0\n",
      "      - 354.0\n",
      "      - 211.0\n",
      "      - 500.0\n",
      "      - 274.0\n",
      "      - 126.0\n",
      "      - 209.0\n",
      "      - 137.0\n",
      "      - 124.0\n",
      "      - 228.0\n",
      "      - 116.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06048327397335355\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05916871043412084\n",
      "      mean_inference_ms: 0.6435016989198361\n",
      "      mean_raw_obs_processing_ms: 0.07285610431617875\n",
      "    timesteps_this_iter: 4122\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 5536\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 11.239521026611328\n",
      "          mean_q: 8.824159622192383\n",
      "          mean_td_error: 0.09101419150829315\n",
      "          min_q: 2.8392229080200195\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.36608123779296875\n",
      "        - -0.04259490966796875\n",
      "        - -1.176401138305664\n",
      "        - -0.17188167572021484\n",
      "        - -1.176955223083496\n",
      "        - 3.116440773010254\n",
      "        - -0.35666656494140625\n",
      "        - 0.11172866821289062\n",
      "        - -1.1619153022766113\n",
      "        - -1.752166748046875\n",
      "        - -0.1780557632446289\n",
      "        - 0.0818948745727539\n",
      "        - 0.17607688903808594\n",
      "        - -1.752166748046875\n",
      "        - -0.0021371841430664062\n",
      "        - -0.15694618225097656\n",
      "        - -1.0194363594055176\n",
      "        - -0.08635520935058594\n",
      "        - 0.11172866821289062\n",
      "        - -0.6845922470092773\n",
      "        - -1.4070367813110352\n",
      "        - 0.11670732498168945\n",
      "        - -0.04057598114013672\n",
      "        - 7.628552436828613\n",
      "        - -0.061466217041015625\n",
      "        - 0.36639404296875\n",
      "        - 1.8392229080200195\n",
      "        - -0.20613765716552734\n",
      "        - -1.3065991401672363\n",
      "        - 3.0840415954589844\n",
      "        - -0.0800924301147461\n",
      "        - -0.5340728759765625\n",
      "    num_agent_steps_sampled: 6000\n",
      "    num_agent_steps_trained: 40032\n",
      "    num_steps_sampled: 6000\n",
      "    num_steps_trained: 40032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 10\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.95555555555555\n",
      "    ram_util_percent: 15.566666666666666\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06729160020089331\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06657874928774037\n",
      "    mean_inference_ms: 0.7365630982311696\n",
      "    mean_raw_obs_processing_ms: 0.1562367928067211\n",
      "  time_since_restore: 21.16961145401001\n",
      "  time_this_iter_s: 6.400044202804565\n",
      "  time_total_s: 21.16961145401001\n",
      "  timers:\n",
      "    learn_throughput: 12613.855\n",
      "    learn_time_ms: 2.537\n",
      "    load_throughput: 301342.003\n",
      "    load_time_ms: 0.106\n",
      "  timestamp: 1671815839\n",
      "  timesteps_since_restore: 192\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 6000\n",
      "  training_iteration: 6\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:21 (running for 00:00:28.95)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">     6</td><td style=\"text-align: right;\">         21.1696</td><td style=\"text-align: right;\">6000</td><td style=\"text-align: right;\">    42.9</td><td style=\"text-align: right;\">                 192</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">              42.9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:27 (running for 00:00:34.49)<br>Memory usage on this node: 4.6/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">     7</td><td style=\"text-align: right;\">          23.663</td><td style=\"text-align: right;\">7000</td><td style=\"text-align: right;\">   49.31</td><td style=\"text-align: right;\">                 192</td><td style=\"text-align: right;\">                   9</td><td style=\"text-align: right;\">             49.31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 8000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-28\n",
      "  done: false\n",
      "  episode_len_mean: 59.02\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 351.0\n",
      "  episode_reward_mean: 59.02\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 191\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 176.95\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 197.0\n",
      "    episode_reward_mean: 176.95\n",
      "    episode_reward_min: 157.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 167\n",
      "      - 171\n",
      "      - 176\n",
      "      - 157\n",
      "      - 181\n",
      "      - 197\n",
      "      - 185\n",
      "      - 180\n",
      "      - 179\n",
      "      - 168\n",
      "      - 171\n",
      "      - 170\n",
      "      - 182\n",
      "      - 173\n",
      "      - 194\n",
      "      - 180\n",
      "      - 175\n",
      "      - 191\n",
      "      - 171\n",
      "      - 171\n",
      "      episode_reward:\n",
      "      - 167.0\n",
      "      - 171.0\n",
      "      - 176.0\n",
      "      - 157.0\n",
      "      - 181.0\n",
      "      - 197.0\n",
      "      - 185.0\n",
      "      - 180.0\n",
      "      - 179.0\n",
      "      - 168.0\n",
      "      - 171.0\n",
      "      - 170.0\n",
      "      - 182.0\n",
      "      - 173.0\n",
      "      - 194.0\n",
      "      - 180.0\n",
      "      - 175.0\n",
      "      - 191.0\n",
      "      - 171.0\n",
      "      - 171.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0615567547631126\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06042527714337524\n",
      "      mean_inference_ms: 0.6517469854735172\n",
      "      mean_raw_obs_processing_ms: 0.07381034504907696\n",
      "    timesteps_this_iter: 3539\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 7552\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 15.67755126953125\n",
      "          mean_q: 11.052631378173828\n",
      "          mean_td_error: 0.8474209308624268\n",
      "          min_q: 0.11968261003494263\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.1854724884033203\n",
      "        - 0.1481027603149414\n",
      "        - -0.19296741485595703\n",
      "        - 0.8556437492370605\n",
      "        - -0.09492111206054688\n",
      "        - -0.7475662231445312\n",
      "        - 0.4047832489013672\n",
      "        - 0.031922340393066406\n",
      "        - 0.6196675300598145\n",
      "        - 0.2897005081176758\n",
      "        - -0.21498489379882812\n",
      "        - 9.999651908874512\n",
      "        - -0.2788662910461426\n",
      "        - 6.304594993591309\n",
      "        - 0.6245441436767578\n",
      "        - 0.7980265617370605\n",
      "        - -0.4497957229614258\n",
      "        - -0.21889972686767578\n",
      "        - -0.8803173899650574\n",
      "        - 3.2972583770751953\n",
      "        - -0.8236026763916016\n",
      "        - -0.30437660217285156\n",
      "        - -0.023929595947265625\n",
      "        - -0.8654384613037109\n",
      "        - 8.455864906311035\n",
      "        - 0.5525913238525391\n",
      "        - 0.07021522521972656\n",
      "        - -0.38569068908691406\n",
      "        - -0.24231243133544922\n",
      "        - -0.40471649169921875\n",
      "        - 0.1910085678100586\n",
      "        - 0.41680908203125\n",
      "    num_agent_steps_sampled: 8000\n",
      "    num_agent_steps_trained: 56032\n",
      "    num_steps_sampled: 8000\n",
      "    num_steps_trained: 56032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 14\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.125\n",
      "    ram_util_percent: 15.149999999999999\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06714208890815103\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06644811037651553\n",
      "    mean_inference_ms: 0.7319190270566256\n",
      "    mean_raw_obs_processing_ms: 0.15454188062066498\n",
      "  time_since_restore: 29.242624521255493\n",
      "  time_this_iter_s: 5.579671144485474\n",
      "  time_total_s: 29.242624521255493\n",
      "  timers:\n",
      "    learn_throughput: 12370.64\n",
      "    learn_time_ms: 2.587\n",
      "    load_throughput: 269675.965\n",
      "    load_time_ms: 0.119\n",
      "  timestamp: 1671815848\n",
      "  timesteps_since_restore: 256\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 8000\n",
      "  training_iteration: 8\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:32 (running for 00:00:39.83)<br>Memory usage on this node: 4.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">     9</td><td style=\"text-align: right;\">         31.9712</td><td style=\"text-align: right;\">9000</td><td style=\"text-align: right;\">   67.93</td><td style=\"text-align: right;\">                 351</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             67.93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 10000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-35\n",
      "  done: false\n",
      "  episode_len_mean: 77.54\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 351.0\n",
      "  episode_reward_mean: 77.54\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 202\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 112.85\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 140.0\n",
      "    episode_reward_mean: 112.85\n",
      "    episode_reward_min: 96.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 105\n",
      "      - 101\n",
      "      - 122\n",
      "      - 99\n",
      "      - 117\n",
      "      - 116\n",
      "      - 140\n",
      "      - 125\n",
      "      - 105\n",
      "      - 107\n",
      "      - 96\n",
      "      - 120\n",
      "      - 114\n",
      "      - 125\n",
      "      - 102\n",
      "      - 119\n",
      "      - 114\n",
      "      - 123\n",
      "      - 110\n",
      "      - 97\n",
      "      episode_reward:\n",
      "      - 105.0\n",
      "      - 101.0\n",
      "      - 122.0\n",
      "      - 99.0\n",
      "      - 117.0\n",
      "      - 116.0\n",
      "      - 140.0\n",
      "      - 125.0\n",
      "      - 105.0\n",
      "      - 107.0\n",
      "      - 96.0\n",
      "      - 120.0\n",
      "      - 114.0\n",
      "      - 125.0\n",
      "      - 102.0\n",
      "      - 119.0\n",
      "      - 114.0\n",
      "      - 123.0\n",
      "      - 110.0\n",
      "      - 97.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06054907185956544\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05930594242882466\n",
      "      mean_inference_ms: 0.6417997991943837\n",
      "      mean_raw_obs_processing_ms: 0.07288182825571068\n",
      "    timesteps_this_iter: 2257\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 9568\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 18.98008155822754\n",
      "          mean_q: 15.307510375976562\n",
      "          mean_td_error: 0.3205712139606476\n",
      "          min_q: -0.5624090433120728\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.06878852844238281\n",
      "        - -0.19887161254882812\n",
      "        - -0.2452373504638672\n",
      "        - -0.09025192260742188\n",
      "        - 0.06837844848632812\n",
      "        - 0.296295166015625\n",
      "        - 0.1267871856689453\n",
      "        - -0.000362396240234375\n",
      "        - 0.025787353515625\n",
      "        - -0.10245323181152344\n",
      "        - 1.5518364906311035\n",
      "        - 0.1278553009033203\n",
      "        - 8.738481521606445\n",
      "        - 0.6284923553466797\n",
      "        - -0.3395347595214844\n",
      "        - 0.07489967346191406\n",
      "        - 0.09295272827148438\n",
      "        - 0.27554798126220703\n",
      "        - 0.045452117919921875\n",
      "        - -0.1454753875732422\n",
      "        - -0.41701698303222656\n",
      "        - 0.5741386413574219\n",
      "        - -0.027242660522460938\n",
      "        - -0.5887546539306641\n",
      "        - -0.1631183624267578\n",
      "        - 0.15247344970703125\n",
      "        - 0.014560699462890625\n",
      "        - -0.09705352783203125\n",
      "        - 1.4736160039901733\n",
      "        - -0.12084388732910156\n",
      "        - -1.5624090433120728\n",
      "        - 0.02056121826171875\n",
      "    num_agent_steps_sampled: 10000\n",
      "    num_agent_steps_trained: 72032\n",
      "    num_steps_sampled: 10000\n",
      "    num_steps_trained: 72032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 18\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 50.48571428571429\n",
      "    ram_util_percent: 14.914285714285715\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06702967497134818\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06626563678200154\n",
      "    mean_inference_ms: 0.7289293261393932\n",
      "    mean_raw_obs_processing_ms: 0.15325290653841234\n",
      "  time_since_restore: 36.67310881614685\n",
      "  time_this_iter_s: 4.701892852783203\n",
      "  time_total_s: 36.67310881614685\n",
      "  timers:\n",
      "    learn_throughput: 14165.908\n",
      "    learn_time_ms: 2.259\n",
      "    load_throughput: 304210.626\n",
      "    load_time_ms: 0.105\n",
      "  timestamp: 1671815855\n",
      "  timesteps_since_restore: 320\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 10000\n",
      "  training_iteration: 10\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:38 (running for 00:00:45.00)<br>Memory usage on this node: 4.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         39.0969</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">   86.42</td><td style=\"text-align: right;\">                 351</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             86.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:43 (running for 00:00:50.01)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">         39.0969</td><td style=\"text-align: right;\">11000</td><td style=\"text-align: right;\">   86.42</td><td style=\"text-align: right;\">                 351</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">             86.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 12000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-43\n",
      "  done: false\n",
      "  episode_len_mean: 94.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 351.0\n",
      "  episode_reward_mean: 94.41\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 215\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 159.25\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 176.0\n",
      "    episode_reward_mean: 159.25\n",
      "    episode_reward_min: 136.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 164\n",
      "      - 160\n",
      "      - 136\n",
      "      - 152\n",
      "      - 165\n",
      "      - 162\n",
      "      - 159\n",
      "      - 169\n",
      "      - 147\n",
      "      - 142\n",
      "      - 160\n",
      "      - 173\n",
      "      - 158\n",
      "      - 176\n",
      "      - 175\n",
      "      - 140\n",
      "      - 167\n",
      "      - 155\n",
      "      - 162\n",
      "      - 163\n",
      "      episode_reward:\n",
      "      - 164.0\n",
      "      - 160.0\n",
      "      - 136.0\n",
      "      - 152.0\n",
      "      - 165.0\n",
      "      - 162.0\n",
      "      - 159.0\n",
      "      - 169.0\n",
      "      - 147.0\n",
      "      - 142.0\n",
      "      - 160.0\n",
      "      - 173.0\n",
      "      - 158.0\n",
      "      - 176.0\n",
      "      - 175.0\n",
      "      - 140.0\n",
      "      - 167.0\n",
      "      - 155.0\n",
      "      - 162.0\n",
      "      - 163.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.062546258241253\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06139842456069183\n",
      "      mean_inference_ms: 0.6582017197922787\n",
      "      mean_raw_obs_processing_ms: 0.0750446283815056\n",
      "    timesteps_this_iter: 3185\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 11584\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 22.733266830444336\n",
      "          mean_q: 19.339977264404297\n",
      "          mean_td_error: 0.2070550173521042\n",
      "          min_q: 2.801553726196289\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.22867202758789062\n",
      "        - 0.8260707855224609\n",
      "        - 0.7080020904541016\n",
      "        - 0.21588897705078125\n",
      "        - 0.7647037506103516\n",
      "        - 0.24832534790039062\n",
      "        - -2.650890350341797\n",
      "        - 0.15875625610351562\n",
      "        - 0.3222064971923828\n",
      "        - -0.8861503601074219\n",
      "        - 0.3730754852294922\n",
      "        - 0.1395092010498047\n",
      "        - 0.19877052307128906\n",
      "        - 0.33365440368652344\n",
      "        - 0.6047811508178711\n",
      "        - 0.15959596633911133\n",
      "        - -0.2026042938232422\n",
      "        - 0.7563686370849609\n",
      "        - 0.16757774353027344\n",
      "        - 0.1623992919921875\n",
      "        - 1.801553726196289\n",
      "        - 0.16970062255859375\n",
      "        - 1.0643196105957031\n",
      "        - 0.23940658569335938\n",
      "        - -0.608245849609375\n",
      "        - -0.09801101684570312\n",
      "        - -0.046794891357421875\n",
      "        - 0.44841957092285156\n",
      "        - 0.49291419982910156\n",
      "        - 0.19671249389648438\n",
      "        - 0.03783226013183594\n",
      "        - 0.2992401123046875\n",
      "    num_agent_steps_sampled: 12000\n",
      "    num_agent_steps_trained: 88032\n",
      "    num_steps_sampled: 12000\n",
      "    num_steps_trained: 88032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 22\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 53.7375\n",
      "    ram_util_percent: 15.425\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0668958080664306\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06599961035870844\n",
      "    mean_inference_ms: 0.7248920606023732\n",
      "    mean_raw_obs_processing_ms: 0.15153775836488584\n",
      "  time_since_restore: 44.85325050354004\n",
      "  time_this_iter_s: 5.756381273269653\n",
      "  time_total_s: 44.85325050354004\n",
      "  timers:\n",
      "    learn_throughput: 11689.403\n",
      "    learn_time_ms: 2.738\n",
      "    load_throughput: 247314.774\n",
      "    load_time_ms: 0.129\n",
      "  timestamp: 1671815863\n",
      "  timesteps_since_restore: 384\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 12000\n",
      "  training_iteration: 12\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:48 (running for 00:00:55.55)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    13</td><td style=\"text-align: right;\">         47.5829</td><td style=\"text-align: right;\">13000</td><td style=\"text-align: right;\">  101.97</td><td style=\"text-align: right;\">                 351</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">            101.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 14000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-51\n",
      "  done: false\n",
      "  episode_len_mean: 110.56\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 110.56\n",
      "  episode_reward_min: 10.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 227\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 108.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 111.0\n",
      "    episode_reward_mean: 108.0\n",
      "    episode_reward_min: 104.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 106\n",
      "      - 109\n",
      "      - 106\n",
      "      - 107\n",
      "      - 110\n",
      "      - 105\n",
      "      - 106\n",
      "      - 111\n",
      "      - 110\n",
      "      - 111\n",
      "      - 107\n",
      "      - 111\n",
      "      - 109\n",
      "      - 107\n",
      "      - 111\n",
      "      - 105\n",
      "      - 109\n",
      "      - 108\n",
      "      - 108\n",
      "      - 104\n",
      "      episode_reward:\n",
      "      - 106.0\n",
      "      - 109.0\n",
      "      - 106.0\n",
      "      - 107.0\n",
      "      - 110.0\n",
      "      - 105.0\n",
      "      - 106.0\n",
      "      - 111.0\n",
      "      - 110.0\n",
      "      - 111.0\n",
      "      - 107.0\n",
      "      - 111.0\n",
      "      - 109.0\n",
      "      - 107.0\n",
      "      - 111.0\n",
      "      - 105.0\n",
      "      - 109.0\n",
      "      - 108.0\n",
      "      - 108.0\n",
      "      - 104.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06162811070065174\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06036786257390232\n",
      "      mean_inference_ms: 0.6495752985292714\n",
      "      mean_raw_obs_processing_ms: 0.07409357251269655\n",
      "    timesteps_this_iter: 2160\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 13600\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 26.111665725708008\n",
      "          mean_q: 21.26922607421875\n",
      "          mean_td_error: 0.31564730405807495\n",
      "          min_q: 4.05136775970459\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.3654918670654297\n",
      "        - 1.4958076477050781\n",
      "        - 4.74198055267334\n",
      "        - -0.22128868103027344\n",
      "        - 0.1724700927734375\n",
      "        - 1.1057319641113281\n",
      "        - -0.24443435668945312\n",
      "        - 0.4536457061767578\n",
      "        - -1.51898193359375\n",
      "        - -0.05281829833984375\n",
      "        - -0.24005508422851562\n",
      "        - -0.12941360473632812\n",
      "        - 0.11211013793945312\n",
      "        - -0.23037338256835938\n",
      "        - 1.3689079284667969\n",
      "        - -0.22075462341308594\n",
      "        - -0.19090652465820312\n",
      "        - -0.16259765625\n",
      "        - 0.5552749633789062\n",
      "        - -0.17829132080078125\n",
      "        - 0.32071685791015625\n",
      "        - -0.07685661315917969\n",
      "        - -0.23167991638183594\n",
      "        - -0.043651580810546875\n",
      "        - 0.13489532470703125\n",
      "        - -1.0579166412353516\n",
      "        - -2.3727169036865234\n",
      "        - 4.875601768493652\n",
      "        - -1.1249561309814453\n",
      "        - -0.978611946105957\n",
      "        - 0.1844501495361328\n",
      "        - 4.220917224884033\n",
      "    num_agent_steps_sampled: 14000\n",
      "    num_agent_steps_trained: 104032\n",
      "    num_steps_sampled: 14000\n",
      "    num_steps_trained: 104032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 26\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.699999999999996\n",
      "    ram_util_percent: 15.850000000000001\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06678704003846532\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06578903084502524\n",
      "    mean_inference_ms: 0.7214489894709949\n",
      "    mean_raw_obs_processing_ms: 0.149942048915924\n",
      "  time_since_restore: 52.03345251083374\n",
      "  time_this_iter_s: 4.450592994689941\n",
      "  time_total_s: 52.03345251083374\n",
      "  timers:\n",
      "    learn_throughput: 13674.338\n",
      "    learn_time_ms: 2.34\n",
      "    load_throughput: 288144.543\n",
      "    load_time_ms: 0.111\n",
      "  timestamp: 1671815871\n",
      "  timesteps_since_restore: 448\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 14000\n",
      "  training_iteration: 14\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:54 (running for 00:01:01.55)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    15</td><td style=\"text-align: right;\">         54.5301</td><td style=\"text-align: right;\">15000</td><td style=\"text-align: right;\">  117.69</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  10</td><td style=\"text-align: right;\">            117.69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 16000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-17-57\n",
      "  done: false\n",
      "  episode_len_mean: 125.35\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 125.35\n",
      "  episode_reward_min: 17.0\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 243\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 103.75\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 110.0\n",
      "    episode_reward_mean: 103.75\n",
      "    episode_reward_min: 96.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 98\n",
      "      - 103\n",
      "      - 105\n",
      "      - 107\n",
      "      - 107\n",
      "      - 106\n",
      "      - 105\n",
      "      - 102\n",
      "      - 97\n",
      "      - 104\n",
      "      - 106\n",
      "      - 103\n",
      "      - 98\n",
      "      - 96\n",
      "      - 107\n",
      "      - 106\n",
      "      - 108\n",
      "      - 110\n",
      "      - 106\n",
      "      - 101\n",
      "      episode_reward:\n",
      "      - 98.0\n",
      "      - 103.0\n",
      "      - 105.0\n",
      "      - 107.0\n",
      "      - 107.0\n",
      "      - 106.0\n",
      "      - 105.0\n",
      "      - 102.0\n",
      "      - 97.0\n",
      "      - 104.0\n",
      "      - 106.0\n",
      "      - 103.0\n",
      "      - 98.0\n",
      "      - 96.0\n",
      "      - 107.0\n",
      "      - 106.0\n",
      "      - 108.0\n",
      "      - 110.0\n",
      "      - 106.0\n",
      "      - 101.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.062066327798527984\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06068339634874871\n",
      "      mean_inference_ms: 0.6520306391243267\n",
      "      mean_raw_obs_processing_ms: 0.07453225895481122\n",
      "    timesteps_this_iter: 2075\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 15616\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 29.259357452392578\n",
      "          mean_q: 22.35641860961914\n",
      "          mean_td_error: 0.4786221981048584\n",
      "          min_q: -2.501039743423462\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.015443801879882812\n",
      "        - 0.4347419738769531\n",
      "        - 0.07043266296386719\n",
      "        - 20.409748077392578\n",
      "        - -0.2575206756591797\n",
      "        - 0.054126739501953125\n",
      "        - -0.13074493408203125\n",
      "        - -0.5799961090087891\n",
      "        - -0.30059814453125\n",
      "        - -0.5535268783569336\n",
      "        - -0.13216781616210938\n",
      "        - 0.03299522399902344\n",
      "        - 0.2724494934082031\n",
      "        - -0.12349700927734375\n",
      "        - 7.380080223083496\n",
      "        - 0.030172348022460938\n",
      "        - -2.095947265625\n",
      "        - -3.501039743423462\n",
      "        - -0.15055274963378906\n",
      "        - 0.06964111328125\n",
      "        - -2.7445926666259766\n",
      "        - -0.19771766662597656\n",
      "        - -0.11451911926269531\n",
      "        - -0.3402557373046875\n",
      "        - -0.3389434814453125\n",
      "        - -0.07745361328125\n",
      "        - -0.03885650634765625\n",
      "        - 1.7049283981323242\n",
      "        - -0.9051704406738281\n",
      "        - 0.17496681213378906\n",
      "        - -2.339155673980713\n",
      "        - -0.4115581512451172\n",
      "    num_agent_steps_sampled: 16000\n",
      "    num_agent_steps_trained: 120032\n",
      "    num_steps_sampled: 16000\n",
      "    num_steps_trained: 120032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 30\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 43.699999999999996\n",
      "    ram_util_percent: 15.9\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06673115500212108\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06559216351386589\n",
      "    mean_inference_ms: 0.7183131972288459\n",
      "    mean_raw_obs_processing_ms: 0.14819047244966504\n",
      "  time_since_restore: 58.85931372642517\n",
      "  time_this_iter_s: 4.329195261001587\n",
      "  time_total_s: 58.85931372642517\n",
      "  timers:\n",
      "    learn_throughput: 12783.737\n",
      "    learn_time_ms: 2.503\n",
      "    load_throughput: 257516.746\n",
      "    load_time_ms: 0.124\n",
      "  timestamp: 1671815877\n",
      "  timesteps_since_restore: 512\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 16000\n",
      "  training_iteration: 16\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:17:59 (running for 00:01:06.91)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         58.8593</td><td style=\"text-align: right;\">16000</td><td style=\"text-align: right;\">  125.35</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  17</td><td style=\"text-align: right;\">            125.35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 18000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-05\n",
      "  done: false\n",
      "  episode_len_mean: 133.82\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 133.82\n",
      "  episode_reward_min: 21.0\n",
      "  episodes_this_iter: 8\n",
      "  episodes_total: 259\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 112.9\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 118.0\n",
      "    episode_reward_mean: 112.9\n",
      "    episode_reward_min: 108.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 110\n",
      "      - 111\n",
      "      - 109\n",
      "      - 118\n",
      "      - 109\n",
      "      - 110\n",
      "      - 116\n",
      "      - 114\n",
      "      - 108\n",
      "      - 116\n",
      "      - 117\n",
      "      - 117\n",
      "      - 112\n",
      "      - 111\n",
      "      - 113\n",
      "      - 108\n",
      "      - 113\n",
      "      - 114\n",
      "      - 115\n",
      "      - 117\n",
      "      episode_reward:\n",
      "      - 110.0\n",
      "      - 111.0\n",
      "      - 109.0\n",
      "      - 118.0\n",
      "      - 109.0\n",
      "      - 110.0\n",
      "      - 116.0\n",
      "      - 114.0\n",
      "      - 108.0\n",
      "      - 116.0\n",
      "      - 117.0\n",
      "      - 117.0\n",
      "      - 112.0\n",
      "      - 111.0\n",
      "      - 113.0\n",
      "      - 108.0\n",
      "      - 113.0\n",
      "      - 114.0\n",
      "      - 115.0\n",
      "      - 117.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0614085359419026\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05996330085861582\n",
      "      mean_inference_ms: 0.6461870663958514\n",
      "      mean_raw_obs_processing_ms: 0.07387894488474918\n",
      "    timesteps_this_iter: 2258\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 17632\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 33.46446228027344\n",
      "          mean_q: 27.69097900390625\n",
      "          mean_td_error: 1.1319657564163208\n",
      "          min_q: 6.807446479797363\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.4847259521484375\n",
      "        - -0.09179496765136719\n",
      "        - -0.1295909881591797\n",
      "        - 0.14044952392578125\n",
      "        - 0.2547645568847656\n",
      "        - -0.21058082580566406\n",
      "        - 0.17545318603515625\n",
      "        - 0.2255096435546875\n",
      "        - -0.16140365600585938\n",
      "        - -0.9037604331970215\n",
      "        - 0.5035028457641602\n",
      "        - -0.3585929870605469\n",
      "        - -0.09950637817382812\n",
      "        - -0.11963272094726562\n",
      "        - -0.1914215087890625\n",
      "        - 0.4184379577636719\n",
      "        - -0.4144458770751953\n",
      "        - 1.6528053283691406\n",
      "        - -0.2653846740722656\n",
      "        - 0.7018337249755859\n",
      "        - 0.02674102783203125\n",
      "        - 2.6350297927856445\n",
      "        - 24.547731399536133\n",
      "        - 3.6735363006591797\n",
      "        - 0.3948020935058594\n",
      "        - 0.12176895141601562\n",
      "        - 3.1880111694335938\n",
      "        - -0.0601348876953125\n",
      "        - -0.20513343811035156\n",
      "        - 0.73406982421875\n",
      "        - -0.5372505187988281\n",
      "        - 0.09236526489257812\n",
      "    num_agent_steps_sampled: 18000\n",
      "    num_agent_steps_trained: 136032\n",
      "    num_steps_sampled: 18000\n",
      "    num_steps_trained: 136032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 34\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.0\n",
      "    ram_util_percent: 15.799999999999999\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06674072821709746\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06548459039164412\n",
      "    mean_inference_ms: 0.7161855648383966\n",
      "    mean_raw_obs_processing_ms: 0.14674429633983727\n",
      "  time_since_restore: 66.25143241882324\n",
      "  time_this_iter_s: 4.616701602935791\n",
      "  time_total_s: 66.25143241882324\n",
      "  timers:\n",
      "    learn_throughput: 13764.086\n",
      "    learn_time_ms: 2.325\n",
      "    load_throughput: 287096.744\n",
      "    load_time_ms: 0.111\n",
      "  timestamp: 1671815885\n",
      "  timesteps_since_restore: 576\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 18000\n",
      "  training_iteration: 18\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:05 (running for 00:01:12.36)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         66.2514</td><td style=\"text-align: right;\">18000</td><td style=\"text-align: right;\">  133.82</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  21</td><td style=\"text-align: right;\">            133.82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:11 (running for 00:01:18.00)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">          68.874</td><td style=\"text-align: right;\">19000</td><td style=\"text-align: right;\">  136.04</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  21</td><td style=\"text-align: right;\">            136.04</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 20000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-12\n",
      "  done: false\n",
      "  episode_len_mean: 136.79\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 136.79\n",
      "  episode_reward_min: 32.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 274\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 129.25\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 150.0\n",
      "    episode_reward_mean: 129.25\n",
      "    episode_reward_min: 119.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 132\n",
      "      - 128\n",
      "      - 123\n",
      "      - 123\n",
      "      - 127\n",
      "      - 135\n",
      "      - 126\n",
      "      - 129\n",
      "      - 131\n",
      "      - 139\n",
      "      - 129\n",
      "      - 134\n",
      "      - 119\n",
      "      - 150\n",
      "      - 120\n",
      "      - 134\n",
      "      - 125\n",
      "      - 128\n",
      "      - 120\n",
      "      - 133\n",
      "      episode_reward:\n",
      "      - 132.0\n",
      "      - 128.0\n",
      "      - 123.0\n",
      "      - 123.0\n",
      "      - 127.0\n",
      "      - 135.0\n",
      "      - 126.0\n",
      "      - 129.0\n",
      "      - 131.0\n",
      "      - 139.0\n",
      "      - 129.0\n",
      "      - 134.0\n",
      "      - 119.0\n",
      "      - 150.0\n",
      "      - 120.0\n",
      "      - 134.0\n",
      "      - 125.0\n",
      "      - 128.0\n",
      "      - 120.0\n",
      "      - 133.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06163879440471297\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06026914969021877\n",
      "      mean_inference_ms: 0.6473657212750062\n",
      "      mean_raw_obs_processing_ms: 0.07411712673561621\n",
      "    timesteps_this_iter: 2585\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 19648\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 35.9039306640625\n",
      "          mean_q: 29.018869400024414\n",
      "          mean_td_error: -0.8006703853607178\n",
      "          min_q: -3.753957509994507\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.018339157104492188\n",
      "        - -0.6986923217773438\n",
      "        - -9.163938522338867\n",
      "        - -0.2658195495605469\n",
      "        - -0.7476348876953125\n",
      "        - -0.21453094482421875\n",
      "        - 0.00029754638671875\n",
      "        - -0.5793704986572266\n",
      "        - -4.080131530761719\n",
      "        - -0.004608154296875\n",
      "        - -7.381336212158203\n",
      "        - -0.060741424560546875\n",
      "        - -2.5233688354492188\n",
      "        - -0.057437896728515625\n",
      "        - -0.10844802856445312\n",
      "        - 9.61781120300293\n",
      "        - -0.02391815185546875\n",
      "        - -0.16590118408203125\n",
      "        - 0.19883346557617188\n",
      "        - -0.8467254638671875\n",
      "        - -0.5528793334960938\n",
      "        - -4.753957748413086\n",
      "        - 0.0003871917724609375\n",
      "        - -0.3972339630126953\n",
      "        - -0.6031990051269531\n",
      "        - -0.44081878662109375\n",
      "        - -0.18427276611328125\n",
      "        - -0.3314704895019531\n",
      "        - -0.4306201934814453\n",
      "        - -0.33884429931640625\n",
      "        - -0.2971305847167969\n",
      "        - -0.16741180419921875\n",
      "    num_agent_steps_sampled: 20000\n",
      "    num_agent_steps_trained: 152032\n",
      "    num_steps_sampled: 20000\n",
      "    num_steps_trained: 152032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 38\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.0\n",
      "    ram_util_percent: 15.799999999999999\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06663426177042847\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06528551440028485\n",
      "    mean_inference_ms: 0.7136377921729417\n",
      "    mean_raw_obs_processing_ms: 0.1455633020446879\n",
      "  time_since_restore: 73.59008407592773\n",
      "  time_this_iter_s: 4.716078996658325\n",
      "  time_total_s: 73.59008407592773\n",
      "  timers:\n",
      "    learn_throughput: 13400.867\n",
      "    learn_time_ms: 2.388\n",
      "    load_throughput: 319186.036\n",
      "    load_time_ms: 0.1\n",
      "  timestamp: 1671815892\n",
      "  timesteps_since_restore: 640\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 20000\n",
      "  training_iteration: 20\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:16 (running for 00:01:23.55)<br>Memory usage on this node: 4.9/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    21</td><td style=\"text-align: right;\">         76.3713</td><td style=\"text-align: right;\">21000</td><td style=\"text-align: right;\">  143.91</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  32</td><td style=\"text-align: right;\">            143.91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 22000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-20\n",
      "  done: false\n",
      "  episode_len_mean: 144.63\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 144.63\n",
      "  episode_reward_min: 40.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 287\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 157.1\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 180.0\n",
      "    episode_reward_mean: 157.1\n",
      "    episode_reward_min: 140.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 149\n",
      "      - 154\n",
      "      - 159\n",
      "      - 170\n",
      "      - 172\n",
      "      - 159\n",
      "      - 140\n",
      "      - 154\n",
      "      - 157\n",
      "      - 180\n",
      "      - 164\n",
      "      - 160\n",
      "      - 165\n",
      "      - 144\n",
      "      - 150\n",
      "      - 150\n",
      "      - 157\n",
      "      - 142\n",
      "      - 165\n",
      "      - 151\n",
      "      episode_reward:\n",
      "      - 149.0\n",
      "      - 154.0\n",
      "      - 159.0\n",
      "      - 170.0\n",
      "      - 172.0\n",
      "      - 159.0\n",
      "      - 140.0\n",
      "      - 154.0\n",
      "      - 157.0\n",
      "      - 180.0\n",
      "      - 164.0\n",
      "      - 160.0\n",
      "      - 165.0\n",
      "      - 144.0\n",
      "      - 150.0\n",
      "      - 150.0\n",
      "      - 157.0\n",
      "      - 142.0\n",
      "      - 165.0\n",
      "      - 151.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06114946097223202\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059708050459136484\n",
      "      mean_inference_ms: 0.642917483951035\n",
      "      mean_raw_obs_processing_ms: 0.0735823997190155\n",
      "    timesteps_this_iter: 3142\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 21664\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 39.3005485534668\n",
      "          mean_q: 31.089561462402344\n",
      "          mean_td_error: 2.611032009124756\n",
      "          min_q: -5.796488285064697\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.3617401123046875\n",
      "        - -0.1833038330078125\n",
      "        - 3.6256937980651855\n",
      "        - 0.22421646118164062\n",
      "        - 26.543048858642578\n",
      "        - 1.0323524475097656\n",
      "        - 0.079010009765625\n",
      "        - 26.101158142089844\n",
      "        - -0.01850128173828125\n",
      "        - 0.22294235229492188\n",
      "        - 0.4472389221191406\n",
      "        - 0.11725234985351562\n",
      "        - 0.6640167236328125\n",
      "        - -0.18722915649414062\n",
      "        - 0.4745521545410156\n",
      "        - -0.8664951324462891\n",
      "        - 0.31589508056640625\n",
      "        - 3.166896343231201\n",
      "        - -0.8445377349853516\n",
      "        - 25.15312957763672\n",
      "        - 0.4619331359863281\n",
      "        - -0.5684661865234375\n",
      "        - -1.9905033111572266\n",
      "        - -0.2118377685546875\n",
      "        - 0.061840057373046875\n",
      "        - -1.0608224868774414\n",
      "        - 0.10037612915039062\n",
      "        - -1.0397872924804688\n",
      "        - 0.09021759033203125\n",
      "        - 1.1651611328125\n",
      "        - 0.44216156005859375\n",
      "        - 0.39715576171875\n",
      "    num_agent_steps_sampled: 22000\n",
      "    num_agent_steps_trained: 168032\n",
      "    num_steps_sampled: 22000\n",
      "    num_steps_trained: 168032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 42\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.6875\n",
      "    ram_util_percent: 15.225000000000001\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06668080572648677\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06526559268171869\n",
      "    mean_inference_ms: 0.7129426448228383\n",
      "    mean_raw_obs_processing_ms: 0.14497535125644126\n",
      "  time_since_restore: 81.75175213813782\n",
      "  time_this_iter_s: 5.380479097366333\n",
      "  time_total_s: 81.75175213813782\n",
      "  timers:\n",
      "    learn_throughput: 13968.645\n",
      "    learn_time_ms: 2.291\n",
      "    load_throughput: 333958.019\n",
      "    load_time_ms: 0.096\n",
      "  timestamp: 1671815900\n",
      "  timesteps_since_restore: 704\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 22000\n",
      "  training_iteration: 22\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:21 (running for 00:01:28.96)<br>Memory usage on this node: 4.7/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    22</td><td style=\"text-align: right;\">         81.7518</td><td style=\"text-align: right;\">22000</td><td style=\"text-align: right;\">  144.63</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  40</td><td style=\"text-align: right;\">            144.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:27 (running for 00:01:34.47)<br>Memory usage on this node: 4.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    23</td><td style=\"text-align: right;\">          84.245</td><td style=\"text-align: right;\">23000</td><td style=\"text-align: right;\">  140.99</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            140.99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 24000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-28\n",
      "  done: false\n",
      "  episode_len_mean: 138.11\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 138.11\n",
      "  episode_reward_min: 97.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 303\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 124.7\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 132.0\n",
      "    episode_reward_mean: 124.7\n",
      "    episode_reward_min: 118.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 132\n",
      "      - 131\n",
      "      - 118\n",
      "      - 130\n",
      "      - 131\n",
      "      - 122\n",
      "      - 123\n",
      "      - 123\n",
      "      - 129\n",
      "      - 121\n",
      "      - 124\n",
      "      - 121\n",
      "      - 126\n",
      "      - 119\n",
      "      - 125\n",
      "      - 125\n",
      "      - 120\n",
      "      - 125\n",
      "      - 125\n",
      "      - 124\n",
      "      episode_reward:\n",
      "      - 132.0\n",
      "      - 131.0\n",
      "      - 118.0\n",
      "      - 130.0\n",
      "      - 131.0\n",
      "      - 122.0\n",
      "      - 123.0\n",
      "      - 123.0\n",
      "      - 129.0\n",
      "      - 121.0\n",
      "      - 124.0\n",
      "      - 121.0\n",
      "      - 126.0\n",
      "      - 119.0\n",
      "      - 125.0\n",
      "      - 125.0\n",
      "      - 120.0\n",
      "      - 125.0\n",
      "      - 125.0\n",
      "      - 124.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06158143933040683\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06017446463604803\n",
      "      mean_inference_ms: 0.6465213757500887\n",
      "      mean_raw_obs_processing_ms: 0.07407491288554471\n",
      "    timesteps_this_iter: 2494\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 23680\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 42.30995178222656\n",
      "          mean_q: 35.197269439697266\n",
      "          mean_td_error: 2.867894172668457\n",
      "          min_q: 9.290846824645996\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.347259521484375\n",
      "        - -1.0586624145507812\n",
      "        - -0.4747123718261719\n",
      "        - -0.6020431518554688\n",
      "        - 2.8497982025146484\n",
      "        - 27.686357498168945\n",
      "        - -0.7446556091308594\n",
      "        - 3.9181666374206543\n",
      "        - -0.18275833129882812\n",
      "        - 0.9528541564941406\n",
      "        - 0.395233154296875\n",
      "        - -1.2071418762207031\n",
      "        - 7.855712890625\n",
      "        - 0.056240081787109375\n",
      "        - 0.13094329833984375\n",
      "        - -0.04424285888671875\n",
      "        - -0.7850418090820312\n",
      "        - -1.36492919921875\n",
      "        - -0.5355033874511719\n",
      "        - -0.8946418762207031\n",
      "        - -0.01568603515625\n",
      "        - 29.636764526367188\n",
      "        - 0.01148223876953125\n",
      "        - -0.6004409790039062\n",
      "        - -0.2885475158691406\n",
      "        - -0.10794448852539062\n",
      "        - -0.9372291564941406\n",
      "        - -0.4205780029296875\n",
      "        - -0.5731544494628906\n",
      "        - 31.005786895751953\n",
      "        - -0.4779243469238281\n",
      "        - -1.063629150390625\n",
      "    num_agent_steps_sampled: 24000\n",
      "    num_agent_steps_trained: 184032\n",
      "    num_steps_sampled: 24000\n",
      "    num_steps_trained: 184032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 46\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.52857142857143\n",
      "    ram_util_percent: 15.200000000000001\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06658389590069987\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06518668843733426\n",
      "    mean_inference_ms: 0.7116284215063451\n",
      "    mean_raw_obs_processing_ms: 0.1443853559997938\n",
      "  time_since_restore: 89.01540803909302\n",
      "  time_this_iter_s: 4.770373344421387\n",
      "  time_total_s: 89.01540803909302\n",
      "  timers:\n",
      "    learn_throughput: 13049.979\n",
      "    learn_time_ms: 2.452\n",
      "    load_throughput: 260263.192\n",
      "    load_time_ms: 0.123\n",
      "  timestamp: 1671815908\n",
      "  timesteps_since_restore: 768\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 24000\n",
      "  training_iteration: 24\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:33 (running for 00:01:40.25)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    25</td><td style=\"text-align: right;\">         91.9563</td><td style=\"text-align: right;\">25000</td><td style=\"text-align: right;\">  137.21</td><td style=\"text-align: right;\">                 372</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            137.21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 26000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-36\n",
      "  done: false\n",
      "  episode_len_mean: 132.47\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 372.0\n",
      "  episode_reward_mean: 132.47\n",
      "  episode_reward_min: 97.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 320\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 117.9\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 125.0\n",
      "    episode_reward_mean: 117.9\n",
      "    episode_reward_min: 113.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 114\n",
      "      - 117\n",
      "      - 118\n",
      "      - 116\n",
      "      - 123\n",
      "      - 118\n",
      "      - 122\n",
      "      - 114\n",
      "      - 117\n",
      "      - 115\n",
      "      - 119\n",
      "      - 117\n",
      "      - 118\n",
      "      - 122\n",
      "      - 113\n",
      "      - 125\n",
      "      - 117\n",
      "      - 113\n",
      "      - 118\n",
      "      - 122\n",
      "      episode_reward:\n",
      "      - 114.0\n",
      "      - 117.0\n",
      "      - 118.0\n",
      "      - 116.0\n",
      "      - 123.0\n",
      "      - 118.0\n",
      "      - 122.0\n",
      "      - 114.0\n",
      "      - 117.0\n",
      "      - 115.0\n",
      "      - 119.0\n",
      "      - 117.0\n",
      "      - 118.0\n",
      "      - 122.0\n",
      "      - 113.0\n",
      "      - 125.0\n",
      "      - 117.0\n",
      "      - 113.0\n",
      "      - 118.0\n",
      "      - 122.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06114881798741693\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05969176189038148\n",
      "      mean_inference_ms: 0.6424454168255278\n",
      "      mean_raw_obs_processing_ms: 0.07365188305647082\n",
      "    timesteps_this_iter: 2358\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 25696\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 44.43935012817383\n",
      "          mean_q: 32.15764617919922\n",
      "          mean_td_error: -0.27023178339004517\n",
      "          min_q: -5.629979610443115\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.038974761962890625\n",
      "        - -0.3344078063964844\n",
      "        - 0.045609474182128906\n",
      "        - -3.5119705200195312\n",
      "        - -0.17383384704589844\n",
      "        - -0.2635917663574219\n",
      "        - 0.042148590087890625\n",
      "        - -2.328746795654297\n",
      "        - -0.3027801513671875\n",
      "        - 0.48116302490234375\n",
      "        - 0.049655914306640625\n",
      "        - -0.2644996643066406\n",
      "        - 4.851663589477539\n",
      "        - 1.0966606140136719\n",
      "        - -0.3204765319824219\n",
      "        - -0.40152508020401\n",
      "        - -4.968843936920166\n",
      "        - -0.421539306640625\n",
      "        - -0.08913803100585938\n",
      "        - 0.39881134033203125\n",
      "        - -0.3689002990722656\n",
      "        - -0.33585357666015625\n",
      "        - -0.170318603515625\n",
      "        - 0.47434234619140625\n",
      "        - -0.4053497314453125\n",
      "        - 0.022289276123046875\n",
      "        - 0.022289276123046875\n",
      "        - -6.629979610443115\n",
      "        - 0.3060798645019531\n",
      "        - -0.3067817687988281\n",
      "        - 4.965091705322266\n",
      "        - 0.156341552734375\n",
      "    num_agent_steps_sampled: 26000\n",
      "    num_agent_steps_trained: 200032\n",
      "    num_steps_sampled: 26000\n",
      "    num_steps_trained: 200032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 50\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.2\n",
      "    ram_util_percent: 15.87142857142857\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0664816838918034\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06519673737942214\n",
      "    mean_inference_ms: 0.7111862379058437\n",
      "    mean_raw_obs_processing_ms: 0.1440980781732473\n",
      "  time_since_restore: 96.75787353515625\n",
      "  time_this_iter_s: 4.8016204833984375\n",
      "  time_total_s: 96.75787353515625\n",
      "  timers:\n",
      "    learn_throughput: 13354.998\n",
      "    learn_time_ms: 2.396\n",
      "    load_throughput: 249058.69\n",
      "    load_time_ms: 0.128\n",
      "  timestamp: 1671815916\n",
      "  timesteps_since_restore: 832\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 26000\n",
      "  training_iteration: 26\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:38 (running for 00:01:45.62)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">          99.254</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">  130.07</td><td style=\"text-align: right;\">                 292</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            130.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:43 (running for 00:01:50.62)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    27</td><td style=\"text-align: right;\">          99.254</td><td style=\"text-align: right;\">27000</td><td style=\"text-align: right;\">  130.07</td><td style=\"text-align: right;\">                 292</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            130.07</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 28000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-47\n",
      "  done: false\n",
      "  episode_len_mean: 135.49\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 135.49\n",
      "  episode_reward_min: 97.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 331\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 380.55\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 441.0\n",
      "    episode_reward_mean: 380.55\n",
      "    episode_reward_min: 340.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 368\n",
      "      - 367\n",
      "      - 360\n",
      "      - 428\n",
      "      - 351\n",
      "      - 369\n",
      "      - 407\n",
      "      - 363\n",
      "      - 364\n",
      "      - 355\n",
      "      - 403\n",
      "      - 360\n",
      "      - 441\n",
      "      - 401\n",
      "      - 389\n",
      "      - 340\n",
      "      - 379\n",
      "      - 406\n",
      "      - 381\n",
      "      - 379\n",
      "      episode_reward:\n",
      "      - 368.0\n",
      "      - 367.0\n",
      "      - 360.0\n",
      "      - 428.0\n",
      "      - 351.0\n",
      "      - 369.0\n",
      "      - 407.0\n",
      "      - 363.0\n",
      "      - 364.0\n",
      "      - 355.0\n",
      "      - 403.0\n",
      "      - 360.0\n",
      "      - 441.0\n",
      "      - 401.0\n",
      "      - 389.0\n",
      "      - 340.0\n",
      "      - 379.0\n",
      "      - 406.0\n",
      "      - 381.0\n",
      "      - 379.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06206450188771197\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06068296110399716\n",
      "      mean_inference_ms: 0.6496983346647933\n",
      "      mean_raw_obs_processing_ms: 0.07425265984750648\n",
      "    timesteps_this_iter: 7611\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 27712\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 46.424156188964844\n",
      "          mean_q: 39.98456954956055\n",
      "          mean_td_error: 1.4370441436767578\n",
      "          min_q: -3.2545154094696045\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 27.22802734375\n",
      "        - -0.09320831298828125\n",
      "        - -0.29877471923828125\n",
      "        - 0.0388031005859375\n",
      "        - -0.13881301879882812\n",
      "        - 0.044353485107421875\n",
      "        - -0.40491485595703125\n",
      "        - -0.1532745361328125\n",
      "        - -0.2612190246582031\n",
      "        - -4.254515647888184\n",
      "        - 0.2385711669921875\n",
      "        - -0.4098320007324219\n",
      "        - -0.22615814208984375\n",
      "        - -0.02693939208984375\n",
      "        - 38.98720169067383\n",
      "        - -0.10728073120117188\n",
      "        - -1.0135574340820312\n",
      "        - -8.218961715698242\n",
      "        - -0.14351272583007812\n",
      "        - 0.4252738952636719\n",
      "        - -3.1332626342773438\n",
      "        - -0.038539886474609375\n",
      "        - -0.771209716796875\n",
      "        - -0.2317047119140625\n",
      "        - -0.5707817077636719\n",
      "        - 0.5314235687255859\n",
      "        - -0.24318695068359375\n",
      "        - 0.005390167236328125\n",
      "        - -0.0431365966796875\n",
      "        - -0.2691459655761719\n",
      "        - -0.20123672485351562\n",
      "        - -0.2604637145996094\n",
      "    num_agent_steps_sampled: 28000\n",
      "    num_agent_steps_trained: 216032\n",
      "    num_steps_sampled: 28000\n",
      "    num_steps_trained: 216032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 54\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 48.94615384615385\n",
      "    ram_util_percent: 16.099999999999998\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06639590382565998\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06516724687151097\n",
      "    mean_inference_ms: 0.7106498050807731\n",
      "    mean_raw_obs_processing_ms: 0.14390064842694894\n",
      "  time_since_restore: 108.6145441532135\n",
      "  time_this_iter_s: 9.360547542572021\n",
      "  time_total_s: 108.6145441532135\n",
      "  timers:\n",
      "    learn_throughput: 12848.843\n",
      "    learn_time_ms: 2.49\n",
      "    load_throughput: 348798.669\n",
      "    load_time_ms: 0.092\n",
      "  timestamp: 1671815927\n",
      "  timesteps_since_restore: 896\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 28000\n",
      "  training_iteration: 28\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:49 (running for 00:01:56.01)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    28</td><td style=\"text-align: right;\">         108.615</td><td style=\"text-align: right;\">28000</td><td style=\"text-align: right;\">  135.49</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            135.49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:54 (running for 00:02:01.53)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    29</td><td style=\"text-align: right;\">         111.139</td><td style=\"text-align: right;\">29000</td><td style=\"text-align: right;\">  138.81</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  97</td><td style=\"text-align: right;\">            138.81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 30000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-18-55\n",
      "  done: false\n",
      "  episode_len_mean: 139.37\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 139.37\n",
      "  episode_reward_min: 100.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 342\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 138.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 144.0\n",
      "    episode_reward_mean: 138.0\n",
      "    episode_reward_min: 130.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 135\n",
      "      - 133\n",
      "      - 139\n",
      "      - 139\n",
      "      - 133\n",
      "      - 141\n",
      "      - 142\n",
      "      - 140\n",
      "      - 141\n",
      "      - 137\n",
      "      - 134\n",
      "      - 130\n",
      "      - 140\n",
      "      - 140\n",
      "      - 144\n",
      "      - 141\n",
      "      - 133\n",
      "      - 142\n",
      "      - 133\n",
      "      - 143\n",
      "      episode_reward:\n",
      "      - 135.0\n",
      "      - 133.0\n",
      "      - 139.0\n",
      "      - 139.0\n",
      "      - 133.0\n",
      "      - 141.0\n",
      "      - 142.0\n",
      "      - 140.0\n",
      "      - 141.0\n",
      "      - 137.0\n",
      "      - 134.0\n",
      "      - 130.0\n",
      "      - 140.0\n",
      "      - 140.0\n",
      "      - 144.0\n",
      "      - 141.0\n",
      "      - 133.0\n",
      "      - 142.0\n",
      "      - 133.0\n",
      "      - 143.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06167201847448561\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.0602573788872378\n",
      "      mean_inference_ms: 0.6461801913544034\n",
      "      mean_raw_obs_processing_ms: 0.07382032922945223\n",
      "    timesteps_this_iter: 2760\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 29728\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 49.42937469482422\n",
      "          mean_q: 43.74293518066406\n",
      "          mean_td_error: -0.06157602369785309\n",
      "          min_q: 1.2579216957092285\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.3124847412109375\n",
      "        - -0.2803306579589844\n",
      "        - 6.223449230194092\n",
      "        - -0.07114410400390625\n",
      "        - -0.7864151000976562\n",
      "        - -0.130828857421875\n",
      "        - -0.6220321655273438\n",
      "        - -0.5937767028808594\n",
      "        - -0.4893760681152344\n",
      "        - -0.012420654296875\n",
      "        - -0.7902259826660156\n",
      "        - -0.2817268371582031\n",
      "        - -0.10680770874023438\n",
      "        - -0.2991943359375\n",
      "        - -1.3105049133300781\n",
      "        - -0.12325286865234375\n",
      "        - -0.21715164184570312\n",
      "        - 0.3732719421386719\n",
      "        - 0.7462158203125\n",
      "        - 0.7493896484375\n",
      "        - -0.9620170593261719\n",
      "        - -1.4269390106201172\n",
      "        - -0.4057579040527344\n",
      "        - -0.8366737365722656\n",
      "        - 0.31463623046875\n",
      "        - -0.4742469787597656\n",
      "        - 0.48610687255859375\n",
      "        - 1.1292438507080078\n",
      "        - -1.3408889770507812\n",
      "        - -0.13098526000976562\n",
      "        - 0.11626815795898438\n",
      "        - -0.10383224487304688\n",
      "    num_agent_steps_sampled: 30000\n",
      "    num_agent_steps_trained: 232032\n",
      "    num_steps_sampled: 30000\n",
      "    num_steps_trained: 232032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 58\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 38.82857142857143\n",
      "    ram_util_percent: 16.042857142857144\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06632205136506171\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06514411338410744\n",
      "    mean_inference_ms: 0.7102183721563813\n",
      "    mean_raw_obs_processing_ms: 0.1437121753100312\n",
      "  time_since_restore: 115.79200267791748\n",
      "  time_this_iter_s: 4.652759313583374\n",
      "  time_total_s: 115.79200267791748\n",
      "  timers:\n",
      "    learn_throughput: 14113.326\n",
      "    learn_time_ms: 2.267\n",
      "    load_throughput: 326087.775\n",
      "    load_time_ms: 0.098\n",
      "  timestamp: 1671815935\n",
      "  timesteps_since_restore: 960\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 30000\n",
      "  training_iteration: 30\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:18:59 (running for 00:02:06.93)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         118.467</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">  143.63</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            143.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:04 (running for 00:02:11.94)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    31</td><td style=\"text-align: right;\">         118.467</td><td style=\"text-align: right;\">31000</td><td style=\"text-align: right;\">  143.63</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                 100</td><td style=\"text-align: right;\">            143.63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 32000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-19-05\n",
      "  done: false\n",
      "  episode_len_mean: 143.29\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 143.29\n",
      "  episode_reward_min: 100.0\n",
      "  episodes_this_iter: 9\n",
      "  episodes_total: 357\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 275.4\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 275.4\n",
      "    episode_reward_min: 168.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 183\n",
      "      - 500\n",
      "      - 184\n",
      "      - 197\n",
      "      - 247\n",
      "      - 296\n",
      "      - 500\n",
      "      - 500\n",
      "      - 270\n",
      "      - 224\n",
      "      - 193\n",
      "      - 500\n",
      "      - 200\n",
      "      - 279\n",
      "      - 194\n",
      "      - 168\n",
      "      - 187\n",
      "      - 170\n",
      "      - 284\n",
      "      - 232\n",
      "      episode_reward:\n",
      "      - 183.0\n",
      "      - 500.0\n",
      "      - 184.0\n",
      "      - 197.0\n",
      "      - 247.0\n",
      "      - 296.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 270.0\n",
      "      - 224.0\n",
      "      - 193.0\n",
      "      - 500.0\n",
      "      - 200.0\n",
      "      - 279.0\n",
      "      - 194.0\n",
      "      - 168.0\n",
      "      - 187.0\n",
      "      - 170.0\n",
      "      - 284.0\n",
      "      - 232.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.061669714969560994\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.060227879221276204\n",
      "      mean_inference_ms: 0.6458871332934246\n",
      "      mean_raw_obs_processing_ms: 0.07370970709452956\n",
      "    timesteps_this_iter: 5508\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 31744\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 49.52245330810547\n",
      "          mean_q: 40.2962760925293\n",
      "          mean_td_error: 1.233412742614746\n",
      "          min_q: -11.177858352661133\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 17.207731246948242\n",
      "        - -0.3660469055175781\n",
      "        - -6.403141021728516\n",
      "        - 0.017818450927734375\n",
      "        - 0.15631484985351562\n",
      "        - -0.2619972229003906\n",
      "        - -1.1410789489746094\n",
      "        - -0.624267578125\n",
      "        - 35.28096389770508\n",
      "        - -1.0978240966796875\n",
      "        - -0.4241523742675781\n",
      "        - -0.4615974426269531\n",
      "        - -4.494060516357422\n",
      "        - -12.177858352661133\n",
      "        - -0.3578147888183594\n",
      "        - -0.17719268798828125\n",
      "        - 0.23844146728515625\n",
      "        - -1.0030479431152344\n",
      "        - 0.021022796630859375\n",
      "        - -0.8697929382324219\n",
      "        - -0.00980377197265625\n",
      "        - -2.1722679138183594\n",
      "        - -0.34778594970703125\n",
      "        - 18.738704681396484\n",
      "        - -0.1751556396484375\n",
      "        - -0.30028533935546875\n",
      "        - 0.26322174072265625\n",
      "        - -1.5989875793457031\n",
      "        - 1.6662063598632812\n",
      "        - 0.5669784545898438\n",
      "        - -0.09489822387695312\n",
      "        - -0.1291351318359375\n",
      "    num_agent_steps_sampled: 32000\n",
      "    num_agent_steps_trained: 248032\n",
      "    num_steps_sampled: 32000\n",
      "    num_steps_trained: 248032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 62\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 49.90909090909091\n",
      "    ram_util_percent: 16.0\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06620633859073483\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06507896631476205\n",
      "    mean_inference_ms: 0.7094263054052764\n",
      "    mean_raw_obs_processing_ms: 0.14343117165315306\n",
      "  time_since_restore: 125.94057559967041\n",
      "  time_this_iter_s: 7.473184585571289\n",
      "  time_total_s: 125.94057559967041\n",
      "  timers:\n",
      "    learn_throughput: 13068.658\n",
      "    learn_time_ms: 2.449\n",
      "    load_throughput: 308617.448\n",
      "    load_time_ms: 0.104\n",
      "  timestamp: 1671815945\n",
      "  timesteps_since_restore: 1024\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 32000\n",
      "  training_iteration: 32\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:10 (running for 00:02:17.96)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    33</td><td style=\"text-align: right;\">          128.44</td><td style=\"text-align: right;\">33000</td><td style=\"text-align: right;\">  142.48</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  89</td><td style=\"text-align: right;\">            142.48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 34000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-19-12\n",
      "  done: false\n",
      "  episode_len_mean: 137.6\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 137.6\n",
      "  episode_reward_min: 89.0\n",
      "  episodes_this_iter: 10\n",
      "  episodes_total: 376\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 97.3\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 102.0\n",
      "    episode_reward_mean: 97.3\n",
      "    episode_reward_min: 90.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 95\n",
      "      - 90\n",
      "      - 101\n",
      "      - 101\n",
      "      - 100\n",
      "      - 99\n",
      "      - 97\n",
      "      - 98\n",
      "      - 102\n",
      "      - 94\n",
      "      - 101\n",
      "      - 96\n",
      "      - 93\n",
      "      - 101\n",
      "      - 101\n",
      "      - 96\n",
      "      - 96\n",
      "      - 96\n",
      "      - 94\n",
      "      - 95\n",
      "      episode_reward:\n",
      "      - 95.0\n",
      "      - 90.0\n",
      "      - 101.0\n",
      "      - 101.0\n",
      "      - 100.0\n",
      "      - 99.0\n",
      "      - 97.0\n",
      "      - 98.0\n",
      "      - 102.0\n",
      "      - 94.0\n",
      "      - 101.0\n",
      "      - 96.0\n",
      "      - 93.0\n",
      "      - 101.0\n",
      "      - 101.0\n",
      "      - 96.0\n",
      "      - 96.0\n",
      "      - 96.0\n",
      "      - 94.0\n",
      "      - 95.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06170935767208844\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.06029246851019573\n",
      "      mean_inference_ms: 0.6464010269077497\n",
      "      mean_raw_obs_processing_ms: 0.07382931854694155\n",
      "    timesteps_this_iter: 1946\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 33760\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 53.26707458496094\n",
      "          mean_q: 46.013824462890625\n",
      "          mean_td_error: -0.04228389263153076\n",
      "          min_q: 13.899471282958984\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -1.7041206359863281\n",
      "        - 0.2548789978027344\n",
      "        - 0.20133209228515625\n",
      "        - 0.11415481567382812\n",
      "        - 0.16124343872070312\n",
      "        - 0.5659561157226562\n",
      "        - -0.14670181274414062\n",
      "        - -0.053127288818359375\n",
      "        - 0.24268341064453125\n",
      "        - 2.5469017028808594\n",
      "        - 0.4193534851074219\n",
      "        - 0.8410148620605469\n",
      "        - -0.013545989990234375\n",
      "        - 0.08101654052734375\n",
      "        - -1.6531791687011719\n",
      "        - 0.1617889404296875\n",
      "        - 0.12946701049804688\n",
      "        - 0.22080230712890625\n",
      "        - 0.1528778076171875\n",
      "        - -12.421859741210938\n",
      "        - 0.1908111572265625\n",
      "        - 0.4223976135253906\n",
      "        - 0.4726142883300781\n",
      "        - 12.899471282958984\n",
      "        - 0.22999191284179688\n",
      "        - -0.0623321533203125\n",
      "        - -1.9772377014160156\n",
      "        - -0.061161041259765625\n",
      "        - -4.149559020996094\n",
      "        - 0.41355133056640625\n",
      "        - 0.0548553466796875\n",
      "        - 0.11257553100585938\n",
      "    num_agent_steps_sampled: 34000\n",
      "    num_agent_steps_trained: 264032\n",
      "    num_steps_sampled: 34000\n",
      "    num_steps_trained: 264032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 66\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.46666666666667\n",
      "    ram_util_percent: 16.0\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06607283196587889\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06499387523699837\n",
      "    mean_inference_ms: 0.7085073068836075\n",
      "    mean_raw_obs_processing_ms: 0.143105515490996\n",
      "  time_since_restore: 132.65052270889282\n",
      "  time_this_iter_s: 4.210289239883423\n",
      "  time_total_s: 132.65052270889282\n",
      "  timers:\n",
      "    learn_throughput: 12350.15\n",
      "    learn_time_ms: 2.591\n",
      "    load_throughput: 303385.461\n",
      "    load_time_ms: 0.105\n",
      "  timestamp: 1671815952\n",
      "  timesteps_since_restore: 1088\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 34000\n",
      "  training_iteration: 34\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:16 (running for 00:02:23.06)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    35</td><td style=\"text-align: right;\">         135.521</td><td style=\"text-align: right;\">35000</td><td style=\"text-align: right;\">  133.53</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            133.53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 36000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-19-20\n",
      "  done: false\n",
      "  episode_len_mean: 136.41\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 136.41\n",
      "  episode_reward_min: 63.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 390\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 160.6\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 189.0\n",
      "    episode_reward_mean: 160.6\n",
      "    episode_reward_min: 146.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 172\n",
      "      - 147\n",
      "      - 156\n",
      "      - 152\n",
      "      - 158\n",
      "      - 157\n",
      "      - 155\n",
      "      - 149\n",
      "      - 146\n",
      "      - 155\n",
      "      - 189\n",
      "      - 175\n",
      "      - 158\n",
      "      - 165\n",
      "      - 171\n",
      "      - 175\n",
      "      - 150\n",
      "      - 176\n",
      "      - 157\n",
      "      - 149\n",
      "      episode_reward:\n",
      "      - 172.0\n",
      "      - 147.0\n",
      "      - 156.0\n",
      "      - 152.0\n",
      "      - 158.0\n",
      "      - 157.0\n",
      "      - 155.0\n",
      "      - 149.0\n",
      "      - 146.0\n",
      "      - 155.0\n",
      "      - 189.0\n",
      "      - 175.0\n",
      "      - 158.0\n",
      "      - 165.0\n",
      "      - 171.0\n",
      "      - 175.0\n",
      "      - 150.0\n",
      "      - 176.0\n",
      "      - 157.0\n",
      "      - 149.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0613476058512699\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05990708315813983\n",
      "      mean_inference_ms: 0.6430966852156668\n",
      "      mean_raw_obs_processing_ms: 0.07342322399533932\n",
      "    timesteps_this_iter: 3212\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 35776\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 53.67206954956055\n",
      "          mean_q: 45.56143569946289\n",
      "          mean_td_error: 2.1093811988830566\n",
      "          min_q: -1.6716785430908203\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.3752479553222656\n",
      "        - -0.14132308959960938\n",
      "        - -0.9033203125\n",
      "        - 33.9644660949707\n",
      "        - -2.1640777587890625\n",
      "        - 0.41109466552734375\n",
      "        - -0.6800346374511719\n",
      "        - -1.501953125\n",
      "        - -0.1736297607421875\n",
      "        - 33.5560302734375\n",
      "        - 0.0119781494140625\n",
      "        - -0.3521881103515625\n",
      "        - -1.0456275939941406\n",
      "        - -0.2600822448730469\n",
      "        - 1.5261917114257812\n",
      "        - -0.49532318115234375\n",
      "        - -0.8180656433105469\n",
      "        - -2.3110809326171875\n",
      "        - -0.8333816528320312\n",
      "        - 14.619919776916504\n",
      "        - 1.0312423706054688\n",
      "        - -0.2037811279296875\n",
      "        - -0.2631950378417969\n",
      "        - 0.04520416259765625\n",
      "        - -0.18111419677734375\n",
      "        - 0.11236953735351562\n",
      "        - 0.2070159912109375\n",
      "        - -2.6716785430908203\n",
      "        - 0.046184539794921875\n",
      "        - -0.6663818359375\n",
      "        - -0.16522216796875\n",
      "        - -1.8247871398925781\n",
      "    num_agent_steps_sampled: 36000\n",
      "    num_agent_steps_trained: 280032\n",
      "    num_steps_sampled: 36000\n",
      "    num_steps_trained: 280032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 70\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 45.912499999999994\n",
      "    ram_util_percent: 16.0\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06599810414321824\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06494464992074336\n",
      "    mean_inference_ms: 0.7079977271328285\n",
      "    mean_raw_obs_processing_ms: 0.14292297236308338\n",
      "  time_since_restore: 140.91057991981506\n",
      "  time_this_iter_s: 5.389622688293457\n",
      "  time_total_s: 140.91057991981506\n",
      "  timers:\n",
      "    learn_throughput: 14081.343\n",
      "    learn_time_ms: 2.273\n",
      "    load_throughput: 281025.394\n",
      "    load_time_ms: 0.114\n",
      "  timestamp: 1671815960\n",
      "  timesteps_since_restore: 1152\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 36000\n",
      "  training_iteration: 36\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:21 (running for 00:02:28.51)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    36</td><td style=\"text-align: right;\">         140.911</td><td style=\"text-align: right;\">36000</td><td style=\"text-align: right;\">  136.41</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            136.41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:27 (running for 00:02:34.04)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    37</td><td style=\"text-align: right;\">         143.444</td><td style=\"text-align: right;\">37000</td><td style=\"text-align: right;\">  137.78</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            137.78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 38000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-19-28\n",
      "  done: false\n",
      "  episode_len_mean: 145.33\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 145.33\n",
      "  episode_reward_min: 63.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 398\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 159.5\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 180.0\n",
      "    episode_reward_mean: 159.5\n",
      "    episode_reward_min: 146.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 165\n",
      "      - 169\n",
      "      - 180\n",
      "      - 157\n",
      "      - 146\n",
      "      - 169\n",
      "      - 149\n",
      "      - 163\n",
      "      - 156\n",
      "      - 160\n",
      "      - 163\n",
      "      - 163\n",
      "      - 155\n",
      "      - 148\n",
      "      - 155\n",
      "      - 152\n",
      "      - 154\n",
      "      - 150\n",
      "      - 178\n",
      "      - 158\n",
      "      episode_reward:\n",
      "      - 165.0\n",
      "      - 169.0\n",
      "      - 180.0\n",
      "      - 157.0\n",
      "      - 146.0\n",
      "      - 169.0\n",
      "      - 149.0\n",
      "      - 163.0\n",
      "      - 156.0\n",
      "      - 160.0\n",
      "      - 163.0\n",
      "      - 163.0\n",
      "      - 155.0\n",
      "      - 148.0\n",
      "      - 155.0\n",
      "      - 152.0\n",
      "      - 154.0\n",
      "      - 150.0\n",
      "      - 178.0\n",
      "      - 158.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.061704628196843345\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.060290294798877944\n",
      "      mean_inference_ms: 0.6459260295625715\n",
      "      mean_raw_obs_processing_ms: 0.0738010568274907\n",
      "    timesteps_this_iter: 3190\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 37792\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 56.450618743896484\n",
      "          mean_q: 49.60888671875\n",
      "          mean_td_error: -0.08799630403518677\n",
      "          min_q: 16.103473663330078\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.292449951171875\n",
      "        - -1.0129623413085938\n",
      "        - 0.25518798828125\n",
      "        - -0.055477142333984375\n",
      "        - 0.630645751953125\n",
      "        - -0.03200531005859375\n",
      "        - 0.54351806640625\n",
      "        - 0.275146484375\n",
      "        - 0.01888275146484375\n",
      "        - 0.3998565673828125\n",
      "        - -3.2569141387939453\n",
      "        - 0.836151123046875\n",
      "        - -0.08901596069335938\n",
      "        - 0.5089530944824219\n",
      "        - 0.4512443542480469\n",
      "        - 0.5269660949707031\n",
      "        - -0.14654541015625\n",
      "        - 0.20856475830078125\n",
      "        - -0.15564727783203125\n",
      "        - 0.10866546630859375\n",
      "        - 0.5976295471191406\n",
      "        - 0.3288459777832031\n",
      "        - 0.6100616455078125\n",
      "        - 1.1645622253417969\n",
      "        - 0.35465240478515625\n",
      "        - -0.2845306396484375\n",
      "        - -7.237089157104492\n",
      "        - 0.19127273559570312\n",
      "        - 0.1820220947265625\n",
      "        - 0.5749053955078125\n",
      "        - 0.16892051696777344\n",
      "        - 0.22520065307617188\n",
      "    num_agent_steps_sampled: 38000\n",
      "    num_agent_steps_trained: 296032\n",
      "    num_steps_sampled: 38000\n",
      "    num_steps_trained: 296032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 74\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 46.125\n",
      "    ram_util_percent: 16.0125\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.065967376724237\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06492604144652683\n",
      "    mean_inference_ms: 0.7078122367691028\n",
      "    mean_raw_obs_processing_ms: 0.14283708358102779\n",
      "  time_since_restore: 148.91512441635132\n",
      "  time_this_iter_s: 5.470966577529907\n",
      "  time_total_s: 148.91512441635132\n",
      "  timers:\n",
      "    learn_throughput: 12851.673\n",
      "    learn_time_ms: 2.49\n",
      "    load_throughput: 313886.174\n",
      "    load_time_ms: 0.102\n",
      "  timestamp: 1671815968\n",
      "  timesteps_since_restore: 1216\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 38000\n",
      "  training_iteration: 38\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:32 (running for 00:02:39.59)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         151.901</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  150.64</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            150.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:37 (running for 00:02:44.59)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    39</td><td style=\"text-align: right;\">         151.901</td><td style=\"text-align: right;\">39000</td><td style=\"text-align: right;\">  150.64</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            150.64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 40000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-19-42\n",
      "  done: false\n",
      "  episode_len_mean: 150.59\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 150.59\n",
      "  episode_reward_min: 63.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 409\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06115007883740936\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059665639941315185\n",
      "      mean_inference_ms: 0.6412265594726387\n",
      "      mean_raw_obs_processing_ms: 0.0729376913558895\n",
      "    timesteps_this_iter: 10000\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 39808\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 57.49246597290039\n",
      "          mean_q: 46.98146057128906\n",
      "          mean_td_error: 1.310775637626648\n",
      "          min_q: -1.2743301391601562\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -4.000556945800781\n",
      "        - 0.2637481689453125\n",
      "        - 0.11873245239257812\n",
      "        - -0.5671844482421875\n",
      "        - -0.24543380737304688\n",
      "        - 0.1952056884765625\n",
      "        - -2.2743301391601562\n",
      "        - 0.00960540771484375\n",
      "        - 0.3889350891113281\n",
      "        - 0.32358551025390625\n",
      "        - -1.1469039916992188\n",
      "        - 0.146270751953125\n",
      "        - 0.23472976684570312\n",
      "        - -0.5815544128417969\n",
      "        - -5.069248199462891\n",
      "        - 0.3921775817871094\n",
      "        - 17.970773696899414\n",
      "        - 0.15966033935546875\n",
      "        - 0.12302398681640625\n",
      "        - -0.24689865112304688\n",
      "        - 0.15100860595703125\n",
      "        - -0.32037353515625\n",
      "        - 36.58238983154297\n",
      "        - 0.2554283142089844\n",
      "        - -0.2625312805175781\n",
      "        - -0.10837936401367188\n",
      "        - -1.0943374633789062\n",
      "        - 0.27170562744140625\n",
      "        - -2.0054149627685547\n",
      "        - 0.42364501953125\n",
      "        - 2.0546181201934814\n",
      "        - -0.19727706909179688\n",
      "    num_agent_steps_sampled: 40000\n",
      "    num_agent_steps_trained: 312032\n",
      "    num_steps_sampled: 40000\n",
      "    num_steps_trained: 312032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 78\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 42.21333333333334\n",
      "    ram_util_percent: 16.059999999999995\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0659248766972305\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06489931878295455\n",
      "    mean_inference_ms: 0.7075017902327962\n",
      "    mean_raw_obs_processing_ms: 0.14272011899346151\n",
      "  time_since_restore: 162.54702067375183\n",
      "  time_this_iter_s: 10.646502017974854\n",
      "  time_total_s: 162.54702067375183\n",
      "  timers:\n",
      "    learn_throughput: 13250.183\n",
      "    learn_time_ms: 2.415\n",
      "    load_throughput: 297073.324\n",
      "    load_time_ms: 0.108\n",
      "  timestamp: 1671815982\n",
      "  timesteps_since_restore: 1280\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 40000\n",
      "  training_iteration: 40\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:43 (running for 00:02:50.24)<br>Memory usage on this node: 5.0/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         162.547</td><td style=\"text-align: right;\">40000</td><td style=\"text-align: right;\">  150.59</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            150.59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:49 (running for 00:02:56.05)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">          165.34</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">   158.4</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">             158.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:54 (running for 00:03:01.09)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    41</td><td style=\"text-align: right;\">          165.34</td><td style=\"text-align: right;\">41000</td><td style=\"text-align: right;\">   158.4</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">             158.4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 42000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-19-55\n",
      "  done: false\n",
      "  episode_len_mean: 164.15\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 164.15\n",
      "  episode_reward_min: 63.0\n",
      "  episodes_this_iter: 2\n",
      "  episodes_total: 413\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0607179557186175\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059205149150874936\n",
      "      mean_inference_ms: 0.6377039765283922\n",
      "      mean_raw_obs_processing_ms: 0.07224278498252351\n",
      "    timesteps_this_iter: 10000\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 41824\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 59.31354522705078\n",
      "          mean_q: 47.05622100830078\n",
      "          mean_td_error: 0.9178475737571716\n",
      "          min_q: -3.17313551902771\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.001995086669921875\n",
      "        - -0.008281707763671875\n",
      "        - -2.7416839599609375\n",
      "        - -3.0215816497802734\n",
      "        - -0.33879852294921875\n",
      "        - -0.02349090576171875\n",
      "        - 0.4758338928222656\n",
      "        - -0.019317626953125\n",
      "        - -1.1645374298095703\n",
      "        - -0.060184478759765625\n",
      "        - 20.29756736755371\n",
      "        - 0.014286041259765625\n",
      "        - -1.5398025512695312\n",
      "        - 0.13854598999023438\n",
      "        - -4.173135757446289\n",
      "        - -0.09183120727539062\n",
      "        - -0.00508880615234375\n",
      "        - -0.438995361328125\n",
      "        - 0.02809906005859375\n",
      "        - -0.6777076721191406\n",
      "        - 18.85871124267578\n",
      "        - 0.06287384033203125\n",
      "        - 0.3551292419433594\n",
      "        - 7.006956100463867\n",
      "        - -0.06485748291015625\n",
      "        - -0.5506744384765625\n",
      "        - -0.033351898193359375\n",
      "        - -0.2986335754394531\n",
      "        - 0.05976104736328125\n",
      "        - 0.06627655029296875\n",
      "        - 0.06469345092773438\n",
      "        - -2.803661346435547\n",
      "    num_agent_steps_sampled: 42000\n",
      "    num_agent_steps_trained: 328032\n",
      "    num_steps_sampled: 42000\n",
      "    num_steps_trained: 328032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 82\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.33749999999999\n",
      "    ram_util_percent: 16.137500000000003\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06590181011851844\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06488183301255014\n",
      "    mean_inference_ms: 0.7073028839858133\n",
      "    mean_raw_obs_processing_ms: 0.14266299365487328\n",
      "  time_since_restore: 176.19957733154297\n",
      "  time_this_iter_s: 10.860064029693604\n",
      "  time_total_s: 176.19957733154297\n",
      "  timers:\n",
      "    learn_throughput: 14142.622\n",
      "    learn_time_ms: 2.263\n",
      "    load_throughput: 299325.888\n",
      "    load_time_ms: 0.107\n",
      "  timestamp: 1671815995\n",
      "  timesteps_since_restore: 1344\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 42000\n",
      "  training_iteration: 42\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:19:59 (running for 00:03:06.93)<br>Memory usage on this node: 4.8/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    43</td><td style=\"text-align: right;\">          179.17</td><td style=\"text-align: right;\">43000</td><td style=\"text-align: right;\">  171.11</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  63</td><td style=\"text-align: right;\">            171.11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 44000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-20-04\n",
      "  done: false\n",
      "  episode_len_mean: 169.92\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 169.92\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 7\n",
      "  episodes_total: 427\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 123.8\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 130.0\n",
      "    episode_reward_mean: 123.8\n",
      "    episode_reward_min: 116.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 130\n",
      "      - 126\n",
      "      - 129\n",
      "      - 126\n",
      "      - 123\n",
      "      - 117\n",
      "      - 128\n",
      "      - 121\n",
      "      - 125\n",
      "      - 127\n",
      "      - 116\n",
      "      - 123\n",
      "      - 130\n",
      "      - 118\n",
      "      - 127\n",
      "      - 130\n",
      "      - 122\n",
      "      - 118\n",
      "      - 120\n",
      "      - 120\n",
      "      episode_reward:\n",
      "      - 130.0\n",
      "      - 126.0\n",
      "      - 129.0\n",
      "      - 126.0\n",
      "      - 123.0\n",
      "      - 117.0\n",
      "      - 128.0\n",
      "      - 121.0\n",
      "      - 125.0\n",
      "      - 127.0\n",
      "      - 116.0\n",
      "      - 123.0\n",
      "      - 130.0\n",
      "      - 118.0\n",
      "      - 127.0\n",
      "      - 130.0\n",
      "      - 122.0\n",
      "      - 118.0\n",
      "      - 120.0\n",
      "      - 120.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06083984333397643\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05932805483604281\n",
      "      mean_inference_ms: 0.6387457974434592\n",
      "      mean_raw_obs_processing_ms: 0.07240223287445205\n",
      "    timesteps_this_iter: 2476\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 43840\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 61.360328674316406\n",
      "          mean_q: 49.82197570800781\n",
      "          mean_td_error: 2.3211190700531006\n",
      "          min_q: 10.19470500946045\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.5257835388183594\n",
      "        - -3.253352165222168\n",
      "        - -0.7552433013916016\n",
      "        - 0.510894775390625\n",
      "        - -0.23932266235351562\n",
      "        - -0.7057113647460938\n",
      "        - 0.3255424499511719\n",
      "        - 0.3279609680175781\n",
      "        - 0.3777122497558594\n",
      "        - -0.33109283447265625\n",
      "        - 0.21498870849609375\n",
      "        - -0.4628562927246094\n",
      "        - -0.1420154571533203\n",
      "        - -0.000667572021484375\n",
      "        - 44.70423889160156\n",
      "        - 0.040302276611328125\n",
      "        - 0.235504150390625\n",
      "        - -0.0858917236328125\n",
      "        - 0.3203086853027344\n",
      "        - 0.15962600708007812\n",
      "        - 0.42293548583984375\n",
      "        - -6.437374114990234\n",
      "        - 0.13973617553710938\n",
      "        - -0.0308380126953125\n",
      "        - 22.29193878173828\n",
      "        - 18.513980865478516\n",
      "        - -1.2467155456542969\n",
      "        - 0.0022430419921875\n",
      "        - -0.047756195068359375\n",
      "        - -0.9256553649902344\n",
      "        - -0.10054779052734375\n",
      "        - -0.07284927368164062\n",
      "    num_agent_steps_sampled: 44000\n",
      "    num_agent_steps_trained: 344032\n",
      "    num_steps_sampled: 44000\n",
      "    num_steps_trained: 344032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 86\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 57.9\n",
      "    ram_util_percent: 15.8\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0658700089909308\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.0648701192963384\n",
      "    mean_inference_ms: 0.7070455903680006\n",
      "    mean_raw_obs_processing_ms: 0.14253281161039102\n",
      "  time_since_restore: 184.36216187477112\n",
      "  time_this_iter_s: 5.191906452178955\n",
      "  time_total_s: 184.36216187477112\n",
      "  timers:\n",
      "    learn_throughput: 10840.971\n",
      "    learn_time_ms: 2.952\n",
      "    load_throughput: 220101.227\n",
      "    load_time_ms: 0.145\n",
      "  timestamp: 1671816004\n",
      "  timesteps_since_restore: 1408\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 44000\n",
      "  training_iteration: 44\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:05 (running for 00:03:12.15)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    44</td><td style=\"text-align: right;\">         184.362</td><td style=\"text-align: right;\">44000</td><td style=\"text-align: right;\">  169.92</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            169.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:10 (running for 00:03:17.72)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    45</td><td style=\"text-align: right;\">         186.912</td><td style=\"text-align: right;\">45000</td><td style=\"text-align: right;\">  161.01</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            161.01</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 46000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-20-11\n",
      "  done: false\n",
      "  episode_len_mean: 164.14\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 164.14\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 4\n",
      "  episodes_total: 439\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 129.45\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 151.0\n",
      "    episode_reward_mean: 129.45\n",
      "    episode_reward_min: 116.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 145\n",
      "      - 131\n",
      "      - 151\n",
      "      - 128\n",
      "      - 121\n",
      "      - 128\n",
      "      - 131\n",
      "      - 135\n",
      "      - 117\n",
      "      - 116\n",
      "      - 118\n",
      "      - 127\n",
      "      - 119\n",
      "      - 126\n",
      "      - 134\n",
      "      - 129\n",
      "      - 135\n",
      "      - 142\n",
      "      - 123\n",
      "      - 133\n",
      "      episode_reward:\n",
      "      - 145.0\n",
      "      - 131.0\n",
      "      - 151.0\n",
      "      - 128.0\n",
      "      - 121.0\n",
      "      - 128.0\n",
      "      - 131.0\n",
      "      - 135.0\n",
      "      - 117.0\n",
      "      - 116.0\n",
      "      - 118.0\n",
      "      - 127.0\n",
      "      - 119.0\n",
      "      - 126.0\n",
      "      - 134.0\n",
      "      - 129.0\n",
      "      - 135.0\n",
      "      - 142.0\n",
      "      - 123.0\n",
      "      - 133.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.060791000317672116\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059270755133343955\n",
      "      mean_inference_ms: 0.6381204765887375\n",
      "      mean_raw_obs_processing_ms: 0.07237770384211918\n",
      "    timesteps_this_iter: 2589\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 45856\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 64.99613189697266\n",
      "          mean_q: 51.714996337890625\n",
      "          mean_td_error: 1.6667981147766113\n",
      "          min_q: -15.172595024108887\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 55.54151153564453\n",
      "        - 0.3258819580078125\n",
      "        - 0.21063995361328125\n",
      "        - 0.30657958984375\n",
      "        - 0.16481781005859375\n",
      "        - -0.2510795593261719\n",
      "        - 2.7231569290161133\n",
      "        - 0.5701713562011719\n",
      "        - 0.3705940246582031\n",
      "        - -0.2939643859863281\n",
      "        - -0.46588134765625\n",
      "        - 0.14150238037109375\n",
      "        - 0.5289535522460938\n",
      "        - -0.19481468200683594\n",
      "        - 0.0220489501953125\n",
      "        - -0.12449264526367188\n",
      "        - -0.120574951171875\n",
      "        - 0.060909271240234375\n",
      "        - -0.5219154357910156\n",
      "        - -0.1484832763671875\n",
      "        - 0.049243927001953125\n",
      "        - 0.3067054748535156\n",
      "        - 0.130767822265625\n",
      "        - 0.22005844116210938\n",
      "        - -16.172595977783203\n",
      "        - 8.730510711669922\n",
      "        - 0.1752777099609375\n",
      "        - -0.19351577758789062\n",
      "        - -0.37557220458984375\n",
      "        - 1.6107559204101562\n",
      "        - -0.38480186462402344\n",
      "        - 0.3951454162597656\n",
      "    num_agent_steps_sampled: 46000\n",
      "    num_agent_steps_trained: 360032\n",
      "    num_steps_sampled: 46000\n",
      "    num_steps_trained: 360032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 90\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 39.67142857142857\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06589848533275053\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06491350198023203\n",
      "    mean_inference_ms: 0.7073410927526215\n",
      "    mean_raw_obs_processing_ms: 0.14252725950744208\n",
      "  time_since_restore: 191.50868010520935\n",
      "  time_this_iter_s: 4.596782922744751\n",
      "  time_total_s: 191.50868010520935\n",
      "  timers:\n",
      "    learn_throughput: 14020.739\n",
      "    learn_time_ms: 2.282\n",
      "    load_throughput: 325613.12\n",
      "    load_time_ms: 0.098\n",
      "  timestamp: 1671816011\n",
      "  timesteps_since_restore: 1472\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 46000\n",
      "  training_iteration: 46\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:16 (running for 00:03:23.26)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    47</td><td style=\"text-align: right;\">         194.414</td><td style=\"text-align: right;\">47000</td><td style=\"text-align: right;\">  167.14</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            167.14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 48000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-20-18\n",
      "  done: false\n",
      "  episode_len_mean: 173.68\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 173.68\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 3\n",
      "  episodes_total: 446\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 95.75\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 100.0\n",
      "    episode_reward_mean: 95.75\n",
      "    episode_reward_min: 91.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 94\n",
      "      - 99\n",
      "      - 93\n",
      "      - 92\n",
      "      - 93\n",
      "      - 95\n",
      "      - 99\n",
      "      - 91\n",
      "      - 94\n",
      "      - 99\n",
      "      - 97\n",
      "      - 95\n",
      "      - 93\n",
      "      - 100\n",
      "      - 96\n",
      "      - 99\n",
      "      - 98\n",
      "      - 99\n",
      "      - 93\n",
      "      - 96\n",
      "      episode_reward:\n",
      "      - 94.0\n",
      "      - 99.0\n",
      "      - 93.0\n",
      "      - 92.0\n",
      "      - 93.0\n",
      "      - 95.0\n",
      "      - 99.0\n",
      "      - 91.0\n",
      "      - 94.0\n",
      "      - 99.0\n",
      "      - 97.0\n",
      "      - 95.0\n",
      "      - 93.0\n",
      "      - 100.0\n",
      "      - 96.0\n",
      "      - 99.0\n",
      "      - 98.0\n",
      "      - 99.0\n",
      "      - 93.0\n",
      "      - 96.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06076302219799053\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059248643555246595\n",
      "      mean_inference_ms: 0.637858290617873\n",
      "      mean_raw_obs_processing_ms: 0.07239253495108938\n",
      "    timesteps_this_iter: 1915\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 47872\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 65.93653106689453\n",
      "          mean_q: 52.52778625488281\n",
      "          mean_td_error: 2.714354991912842\n",
      "          min_q: 7.005611419677734\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.030750274658203125\n",
      "        - 0.4890289306640625\n",
      "        - 33.715301513671875\n",
      "        - -1.8184928894042969\n",
      "        - 17.99536895751953\n",
      "        - 10.499177932739258\n",
      "        - 0.3659782409667969\n",
      "        - 0.11255645751953125\n",
      "        - 0.01216888427734375\n",
      "        - 0.48657989501953125\n",
      "        - 0.7964630126953125\n",
      "        - 0.7027320861816406\n",
      "        - 15.869064331054688\n",
      "        - 0.8409881591796875\n",
      "        - 2.7233352661132812\n",
      "        - 0.3939476013183594\n",
      "        - -0.02175140380859375\n",
      "        - -1.2802047729492188\n",
      "        - -0.1420135498046875\n",
      "        - 0.24176788330078125\n",
      "        - -0.17119598388671875\n",
      "        - 0.10544204711914062\n",
      "        - -0.2663230895996094\n",
      "        - 0.11132049560546875\n",
      "        - -0.6718292236328125\n",
      "        - 0.21928787231445312\n",
      "        - 0.6140556335449219\n",
      "        - 0.29334259033203125\n",
      "        - 0.2738037109375\n",
      "        - -0.029552459716796875\n",
      "        - 3.6998178958892822\n",
      "        - 0.729949951171875\n",
      "    num_agent_steps_sampled: 48000\n",
      "    num_agent_steps_trained: 376032\n",
      "    num_steps_sampled: 48000\n",
      "    num_steps_trained: 376032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 94\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 51.15\n",
      "    ram_util_percent: 16.3\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06593335384748282\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06495893993831339\n",
      "    mean_inference_ms: 0.7076856858763528\n",
      "    mean_raw_obs_processing_ms: 0.14255552722946951\n",
      "  time_since_restore: 198.86000156402588\n",
      "  time_this_iter_s: 4.445586442947388\n",
      "  time_total_s: 198.86000156402588\n",
      "  timers:\n",
      "    learn_throughput: 12074.283\n",
      "    learn_time_ms: 2.65\n",
      "    load_throughput: 225121.986\n",
      "    load_time_ms: 0.142\n",
      "  timestamp: 1671816018\n",
      "  timesteps_since_restore: 1536\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 48000\n",
      "  training_iteration: 48\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:21 (running for 00:03:28.27)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         201.376</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  171.79</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            171.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:26 (running for 00:03:33.31)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         201.376</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  171.79</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            171.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:31 (running for 00:03:38.31)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    49</td><td style=\"text-align: right;\">         201.376</td><td style=\"text-align: right;\">49000</td><td style=\"text-align: right;\">  171.79</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            171.79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 50000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-20-32\n",
      "  done: false\n",
      "  episode_len_mean: 174.72\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 174.72\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 5\n",
      "  episodes_total: 460\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 489.15\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 489.15\n",
      "    episode_reward_min: 382.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 401\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 382\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 401.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 382.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06115325659824293\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.059695306747273816\n",
      "      mean_inference_ms: 0.6408569587463132\n",
      "      mean_raw_obs_processing_ms: 0.07267344838342729\n",
      "    timesteps_this_iter: 9783\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 49888\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 68.08312225341797\n",
      "          mean_q: 54.08698272705078\n",
      "          mean_td_error: -0.15398499369621277\n",
      "          min_q: -7.501542091369629\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.7588653564453125\n",
      "        - 0.03795623779296875\n",
      "        - 0.7488632202148438\n",
      "        - 0.24579620361328125\n",
      "        - 0.5175285339355469\n",
      "        - 0.13829803466796875\n",
      "        - -0.01560211181640625\n",
      "        - 0.2427825927734375\n",
      "        - 0.11098480224609375\n",
      "        - 0.8726425170898438\n",
      "        - 0.05975341796875\n",
      "        - -0.09796142578125\n",
      "        - 0.149749755859375\n",
      "        - -0.24640274047851562\n",
      "        - 0.6497344970703125\n",
      "        - 0.20678329467773438\n",
      "        - 0.4098930358886719\n",
      "        - 0.20419692993164062\n",
      "        - -0.15268707275390625\n",
      "        - 0.3075714111328125\n",
      "        - 0.47869110107421875\n",
      "        - 0.27397918701171875\n",
      "        - -0.8723907470703125\n",
      "        - -1.7956619262695312\n",
      "        - -8.501542091369629\n",
      "        - 1.0350627899169922\n",
      "        - 0.7348518371582031\n",
      "        - 0.8467216491699219\n",
      "        - 0.93017578125\n",
      "        - -3.8919677734375\n",
      "        - 0.162811279296875\n",
      "        - 0.5230026245117188\n",
      "    num_agent_steps_sampled: 50000\n",
      "    num_agent_steps_trained: 392032\n",
      "    num_steps_sampled: 50000\n",
      "    num_steps_trained: 392032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 98\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 47.75625\n",
      "    ram_util_percent: 16.225\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06596979946959801\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06501908515339573\n",
      "    mean_inference_ms: 0.7080816226576911\n",
      "    mean_raw_obs_processing_ms: 0.1425659326214495\n",
      "  time_since_restore: 212.43549633026123\n",
      "  time_this_iter_s: 11.059557914733887\n",
      "  time_total_s: 212.43549633026123\n",
      "  timers:\n",
      "    learn_throughput: 14218.733\n",
      "    learn_time_ms: 2.251\n",
      "    load_throughput: 337909.688\n",
      "    load_time_ms: 0.095\n",
      "  timestamp: 1671816032\n",
      "  timesteps_since_restore: 1600\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 50000\n",
      "  training_iteration: 50\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:36 (running for 00:03:43.91)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    51</td><td style=\"text-align: right;\">         214.966</td><td style=\"text-align: right;\">51000</td><td style=\"text-align: right;\">  179.97</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            179.97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 52000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-20-39\n",
      "  done: false\n",
      "  episode_len_mean: 184.26\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 184.26\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 471\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 105.55\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 112.0\n",
      "    episode_reward_mean: 105.55\n",
      "    episode_reward_min: 101.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 103\n",
      "      - 112\n",
      "      - 104\n",
      "      - 106\n",
      "      - 105\n",
      "      - 106\n",
      "      - 104\n",
      "      - 107\n",
      "      - 107\n",
      "      - 104\n",
      "      - 106\n",
      "      - 104\n",
      "      - 101\n",
      "      - 105\n",
      "      - 107\n",
      "      - 104\n",
      "      - 109\n",
      "      - 107\n",
      "      - 107\n",
      "      - 103\n",
      "      episode_reward:\n",
      "      - 103.0\n",
      "      - 112.0\n",
      "      - 104.0\n",
      "      - 106.0\n",
      "      - 105.0\n",
      "      - 106.0\n",
      "      - 104.0\n",
      "      - 107.0\n",
      "      - 107.0\n",
      "      - 104.0\n",
      "      - 106.0\n",
      "      - 104.0\n",
      "      - 101.0\n",
      "      - 105.0\n",
      "      - 107.0\n",
      "      - 104.0\n",
      "      - 109.0\n",
      "      - 107.0\n",
      "      - 107.0\n",
      "      - 103.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.0610351289800631\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05957197291191706\n",
      "      mean_inference_ms: 0.6398464262656561\n",
      "      mean_raw_obs_processing_ms: 0.0725875270499052\n",
      "    timesteps_this_iter: 2111\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 51904\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 68.49964904785156\n",
      "          mean_q: 57.49397277832031\n",
      "          mean_td_error: 3.4149746894836426\n",
      "          min_q: 8.499631881713867\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.24162673950195312\n",
      "        - -0.04489898681640625\n",
      "        - 0.5095596313476562\n",
      "        - -0.14841079711914062\n",
      "        - 58.30075454711914\n",
      "        - -0.28839111328125\n",
      "        - -3.1816062927246094\n",
      "        - 0.91937255859375\n",
      "        - -1.2135086059570312\n",
      "        - 0.08814239501953125\n",
      "        - -0.277008056640625\n",
      "        - 0.2962379455566406\n",
      "        - -0.16178131103515625\n",
      "        - -0.23032379150390625\n",
      "        - -0.33412933349609375\n",
      "        - 58.79658889770508\n",
      "        - -0.7793960571289062\n",
      "        - -2.3834781646728516\n",
      "        - 0.04840850830078125\n",
      "        - -0.16880035400390625\n",
      "        - -0.23969268798828125\n",
      "        - -0.03592681884765625\n",
      "        - 1.201995849609375\n",
      "        - 0.08978271484375\n",
      "        - -0.2708587646484375\n",
      "        - -0.1666412353515625\n",
      "        - 0.21392822265625\n",
      "        - 0.0243377685546875\n",
      "        - -0.01219940185546875\n",
      "        - -0.20355987548828125\n",
      "        - -0.09229278564453125\n",
      "        - -0.7353897094726562\n",
      "    num_agent_steps_sampled: 52000\n",
      "    num_agent_steps_trained: 408032\n",
      "    num_steps_sampled: 52000\n",
      "    num_steps_trained: 408032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 102\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 37.86\n",
      "    ram_util_percent: 16.2\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06599026516417275\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06506034297550099\n",
      "    mean_inference_ms: 0.7083320203921256\n",
      "    mean_raw_obs_processing_ms: 0.14255579628244605\n",
      "  time_since_restore: 219.11421132087708\n",
      "  time_this_iter_s: 4.1482415199279785\n",
      "  time_total_s: 219.11421132087708\n",
      "  timers:\n",
      "    learn_throughput: 13814.377\n",
      "    learn_time_ms: 2.316\n",
      "    load_throughput: 309471.358\n",
      "    load_time_ms: 0.103\n",
      "  timestamp: 1671816039\n",
      "  timesteps_since_restore: 1664\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 52000\n",
      "  training_iteration: 52\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:42 (running for 00:03:49.81)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    53</td><td style=\"text-align: right;\">         221.806</td><td style=\"text-align: right;\">53000</td><td style=\"text-align: right;\">  187.92</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            187.92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 54000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-20-47\n",
      "  done: false\n",
      "  episode_len_mean: 196.77\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 196.77\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 480\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 129.65\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 146.0\n",
      "    episode_reward_mean: 129.65\n",
      "    episode_reward_min: 120.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 132\n",
      "      - 129\n",
      "      - 120\n",
      "      - 134\n",
      "      - 126\n",
      "      - 124\n",
      "      - 142\n",
      "      - 130\n",
      "      - 120\n",
      "      - 133\n",
      "      - 137\n",
      "      - 123\n",
      "      - 128\n",
      "      - 130\n",
      "      - 126\n",
      "      - 130\n",
      "      - 124\n",
      "      - 146\n",
      "      - 132\n",
      "      - 127\n",
      "      episode_reward:\n",
      "      - 132.0\n",
      "      - 129.0\n",
      "      - 120.0\n",
      "      - 134.0\n",
      "      - 126.0\n",
      "      - 124.0\n",
      "      - 142.0\n",
      "      - 130.0\n",
      "      - 120.0\n",
      "      - 133.0\n",
      "      - 137.0\n",
      "      - 123.0\n",
      "      - 128.0\n",
      "      - 130.0\n",
      "      - 126.0\n",
      "      - 130.0\n",
      "      - 124.0\n",
      "      - 146.0\n",
      "      - 132.0\n",
      "      - 127.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06126085064208749\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05981583344944215\n",
      "      mean_inference_ms: 0.6417690358789323\n",
      "      mean_raw_obs_processing_ms: 0.07288414080257759\n",
      "    timesteps_this_iter: 2593\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 53920\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 71.23887634277344\n",
      "          mean_q: 55.206398010253906\n",
      "          mean_td_error: 2.392707109451294\n",
      "          min_q: 1.187178611755371\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - 0.17346954345703125\n",
      "        - 0.647308349609375\n",
      "        - 0.39069366455078125\n",
      "        - -0.25496673583984375\n",
      "        - 0.55029296875\n",
      "        - -0.12908935546875\n",
      "        - 0.7802581787109375\n",
      "        - 1.1644401550292969\n",
      "        - 0.52191162109375\n",
      "        - -0.8875350952148438\n",
      "        - -0.09190750122070312\n",
      "        - 0.5814113616943359\n",
      "        - 0.6478805541992188\n",
      "        - 0.2959747314453125\n",
      "        - 0.253631591796875\n",
      "        - 0.44853973388671875\n",
      "        - -0.573521614074707\n",
      "        - -1.0758991241455078\n",
      "        - -0.3877105712890625\n",
      "        - 0.0867919921875\n",
      "        - -0.17589569091796875\n",
      "        - -0.5313911437988281\n",
      "        - 0.01595306396484375\n",
      "        - 0.031463623046875\n",
      "        - 1.305642008781433\n",
      "        - 0.5811309814453125\n",
      "        - 0.0128326416015625\n",
      "        - 0.481842041015625\n",
      "        - 4.378286361694336\n",
      "        - -0.17726898193359375\n",
      "        - 0.0673370361328125\n",
      "        - 67.43472290039062\n",
      "    num_agent_steps_sampled: 54000\n",
      "    num_agent_steps_trained: 424032\n",
      "    num_steps_sampled: 54000\n",
      "    num_steps_trained: 424032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 106\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 54.099999999999994\n",
      "    ram_util_percent: 16.2\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.06600995130951387\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06509707506558637\n",
      "    mean_inference_ms: 0.7085578346310356\n",
      "    mean_raw_obs_processing_ms: 0.14254760548288956\n",
      "  time_since_restore: 227.08470582962036\n",
      "  time_this_iter_s: 5.278469800949097\n",
      "  time_total_s: 227.08470582962036\n",
      "  timers:\n",
      "    learn_throughput: 12848.474\n",
      "    learn_time_ms: 2.491\n",
      "    load_throughput: 317449.688\n",
      "    load_time_ms: 0.101\n",
      "  timestamp: 1671816047\n",
      "  timesteps_since_restore: 1728\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 54000\n",
      "  training_iteration: 54\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:48 (running for 00:03:55.12)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    54</td><td style=\"text-align: right;\">         227.085</td><td style=\"text-align: right;\">54000</td><td style=\"text-align: right;\">  196.77</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            196.77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:53 (running for 00:04:00.70)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         229.646</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  195.42</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            195.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:20:58 (running for 00:04:05.73)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    55</td><td style=\"text-align: right;\">         229.646</td><td style=\"text-align: right;\">55000</td><td style=\"text-align: right;\">  195.42</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            195.42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for DQN_CartPole-v1_96fce_00000:\n",
      "  agent_timesteps_total: 56000\n",
      "  custom_metrics: {}\n",
      "  date: 2022-12-23_17-21-00\n",
      "  done: false\n",
      "  episode_len_mean: 197.03\n",
      "  episode_media: {}\n",
      "  episode_reward_max: 500.0\n",
      "  episode_reward_mean: 197.03\n",
      "  episode_reward_min: 53.0\n",
      "  episodes_this_iter: 6\n",
      "  episodes_total: 493\n",
      "  evaluation:\n",
      "    custom_metrics: {}\n",
      "    episode_len_mean: 500.0\n",
      "    episode_media: {}\n",
      "    episode_reward_max: 500.0\n",
      "    episode_reward_mean: 500.0\n",
      "    episode_reward_min: 500.0\n",
      "    episodes_this_iter: 20\n",
      "    hist_stats:\n",
      "      episode_lengths:\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      - 500\n",
      "      episode_reward:\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "      - 500.0\n",
      "    off_policy_estimator: {}\n",
      "    policy_reward_max: {}\n",
      "    policy_reward_mean: {}\n",
      "    policy_reward_min: {}\n",
      "    sampler_perf:\n",
      "      mean_action_processing_ms: 0.06138949494402871\n",
      "      mean_env_render_ms: 0.0\n",
      "      mean_env_wait_ms: 0.05997011251944553\n",
      "      mean_inference_ms: 0.6428768392245544\n",
      "      mean_raw_obs_processing_ms: 0.07296498712986764\n",
      "    timesteps_this_iter: 10000\n",
      "  experiment_id: f330e3f7df2c4daf8079ab723122d6a3\n",
      "  hostname: dl\n",
      "  info:\n",
      "    last_target_update_ts: 55936\n",
      "    learner:\n",
      "      default_policy:\n",
      "        custom_metrics: {}\n",
      "        learner_stats:\n",
      "          cur_lr: 0.0005000000237487257\n",
      "          max_q: 71.78622436523438\n",
      "          mean_q: 52.43104553222656\n",
      "          mean_td_error: 1.4288079738616943\n",
      "          min_q: 7.836528778076172\n",
      "          model: {}\n",
      "        td_error:\n",
      "        - -0.12163543701171875\n",
      "        - -0.1563720703125\n",
      "        - -0.157562255859375\n",
      "        - 0.105804443359375\n",
      "        - 0.6900672912597656\n",
      "        - 0.475006103515625\n",
      "        - 0.8500289916992188\n",
      "        - 0.7507171630859375\n",
      "        - 0.010453224182128906\n",
      "        - 14.444351196289062\n",
      "        - -0.15855789184570312\n",
      "        - 0.0219573974609375\n",
      "        - -2.211761474609375\n",
      "        - -0.5450439453125\n",
      "        - 0.01116180419921875\n",
      "        - -0.42218017578125\n",
      "        - -0.11705780029296875\n",
      "        - -0.4361743927001953\n",
      "        - 0.010453224182128906\n",
      "        - -0.0206451416015625\n",
      "        - -1.2959823608398438\n",
      "        - -0.01311492919921875\n",
      "        - 0.7528076171875\n",
      "        - -0.29561614990234375\n",
      "        - -0.19110870361328125\n",
      "        - -1.1292953491210938\n",
      "        - -0.12701416015625\n",
      "        - -0.035736083984375\n",
      "        - 0.115936279296875\n",
      "        - -1.0683059692382812\n",
      "        - -0.32550048828125\n",
      "        - 36.3117790222168\n",
      "    num_agent_steps_sampled: 56000\n",
      "    num_agent_steps_trained: 440032\n",
      "    num_steps_sampled: 56000\n",
      "    num_steps_trained: 440032\n",
      "    num_steps_trained_this_iter: 32\n",
      "    num_target_updates: 110\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.0.98\n",
      "  num_healthy_workers: 0\n",
      "  off_policy_estimator: {}\n",
      "  perf:\n",
      "    cpu_util_percent: 44.78666666666667\n",
      "    ram_util_percent: 16.29333333333334\n",
      "  pid: 157047\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sampler_perf:\n",
      "    mean_action_processing_ms: 0.0659971158674917\n",
      "    mean_env_render_ms: 0.0\n",
      "    mean_env_wait_ms: 0.06510961780834344\n",
      "    mean_inference_ms: 0.7085379947939997\n",
      "    mean_raw_obs_processing_ms: 0.14247055928925473\n",
      "  time_since_restore: 240.70784401893616\n",
      "  time_this_iter_s: 11.061510801315308\n",
      "  time_total_s: 240.70784401893616\n",
      "  timers:\n",
      "    learn_throughput: 14099.686\n",
      "    learn_time_ms: 2.27\n",
      "    load_throughput: 301952.144\n",
      "    load_time_ms: 0.106\n",
      "  timestamp: 1671816060\n",
      "  timesteps_since_restore: 1792\n",
      "  timesteps_this_iter: 32\n",
      "  timesteps_total: 56000\n",
      "  training_iteration: 56\n",
      "  trial_id: 96fce_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:21:04 (running for 00:04:11.51)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         243.405</td><td style=\"text-align: right;\">57000</td><td style=\"text-align: right;\">  203.02</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            203.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:21:09 (running for 00:04:16.54)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         243.405</td><td style=\"text-align: right;\">57000</td><td style=\"text-align: right;\">  203.02</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            203.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 17:21:13,560\tWARNING tune.py:595 -- SIGINT received (e.g. via Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C one more time (or send SIGINT/SIGKILL/SIGTERM) to skip. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-12-23 17:21:13 (running for 00:04:20.55)<br>Memory usage on this node: 5.1/31.3 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1.0/8 CPUs, 0/2 GPUs, 0.0/16.69 GiB heap, 0.0/8.34 GiB objects (0.0/1.0 accelerator_type:G)<br>Result logdir: /home/oscar/msc/fastdeeprl/17_tensorboard_visualization/cartpole_v1/DQN<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                 </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">   ts</th><th style=\"text-align: right;\">  reward</th><th style=\"text-align: right;\">  episode_reward_max</th><th style=\"text-align: right;\">  episode_reward_min</th><th style=\"text-align: right;\">  episode_len_mean</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DQN_CartPole-v1_96fce_00000</td><td>RUNNING </td><td>192.168.0.98:157047</td><td style=\"text-align: right;\">    57</td><td style=\"text-align: right;\">         243.405</td><td style=\"text-align: right;\">57000</td><td style=\"text-align: right;\">  203.02</td><td style=\"text-align: right;\">                 500</td><td style=\"text-align: right;\">                  53</td><td style=\"text-align: right;\">            203.02</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 17:21:13,767\tERROR tune.py:635 -- Trials did not complete: [DQN_CartPole-v1_96fce_00000]\n",
      "2022-12-23 17:21:13,767\tINFO tune.py:639 -- Total run time: 262.71 seconds (260.55 seconds for the tuning loop).\n",
      "2022-12-23 17:21:13,768\tWARNING tune.py:643 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x7f442b16fbe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "tune.run(\"DQN\",\n",
    "         config={\"env\": \"CartPole-v1\",\n",
    "                 \"evaluation_interval\": 2, \n",
    "                 \"evaluation_num_episodes\": 20,\n",
    "                 },\n",
    "         local_dir=\"cartpole_v1\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8497cc95-37e1-4c5f-9c60-b43c31d6f2bf",
   "metadata": {},
   "source": [
    "## Tensorboard can autodetect different experiments stored under the same results dir\n",
    "\n",
    "- Use `tensorboard logdir=cartpole_v1`\n",
    "\n",
    "```\n",
    "cartpole_v1/\n",
    " DQN\n",
    "  basic-variant-state-2021-06-11_11-46-36.json\n",
    "  DQN_CartPole-v1_e97f1_00000_0_2021-06-11_11-46-36\n",
    "   events.out.tfevents.1623404796.devbox-x299\n",
    "   params.json\n",
    "   params.pkl\n",
    "   progress.csv\n",
    "   result.json\n",
    "  experiment_state-2021-06-11_11-46-36.json\n",
    " PPO\n",
    "     basic-variant-state-2021-06-11_11-46-26.json\n",
    "     experiment_state-2021-06-11_11-46-26.json\n",
    "     PPO_CartPole-v1_e3e63_00000_0_2021-06-11_11-46-26\n",
    "         events.out.tfevents.1623404786.devbox-x299\n",
    "         params.json\n",
    "         params.pkl\n",
    "         progress.csv\n",
    "         result.json\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastdeeprl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "95c71cf0cfca1a30a715643409ef6f02fe6cf59ad20fff67f74f909906b1eae3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
