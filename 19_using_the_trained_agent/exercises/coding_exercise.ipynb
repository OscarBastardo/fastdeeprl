{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2f49e11-ceb5-432f-aa37-51f959315f77",
   "metadata": {},
   "source": [
    "# Create a video of the walking robot\n",
    "\n",
    "By now, the robot should have reached an evaluation performance > 250 cumulative rewards per episode. \n",
    "\n",
    "![250](250.png)\n",
    "\n",
    "That means the robot is able to walk.\n",
    "\n",
    "In this exercise, we will create a video of the walking robot.\n",
    "\n",
    "In the last exercise, you created checkpoints (saved agents) in the relative path `bipedal_walker_v3`. Find the last checkpoint file and use it to restore the agent in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd38675e-b02e-4f45-83fa-922e14248e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 18:44:50,953\tINFO trainer.py:2140 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
      "2022-12-23 18:44:50,959\tWARNING deprecation.py:45 -- DeprecationWarning: `evaluation_num_episodes` has been deprecated. Use ``evaluation_duration` and `evaluation_duration_unit=episodes`` instead. This will raise an error in the future!\n",
      "2022-12-23 18:44:50,960\tINFO ppo.py:249 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.\n",
      "2022-12-23 18:44:50,961\tINFO trainer.py:779 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2022-12-23 18:45:00,551\tWARNING deprecation.py:45 -- DeprecationWarning: `simple_optimizer` has been deprecated. This will raise an error in the future!\n",
      "2022-12-23 18:45:01,558\tINFO trainable.py:127 -- Trainable.setup took 10.609 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2022-12-23 18:45:01,559\tWARNING util.py:55 -- Install gputil for GPU system monitoring.\n",
      "2022-12-23 18:45:01,654\tINFO trainable.py:495 -- Restored on 127.0.0.1 from checkpoint: ../../18_saving_the_trained_agent/exercises/bipedal_walker_v3/PPO/PPO_BipedalWalker-v3_a08d1_00000_0_2022-12-23_17-45-46/checkpoint_000600/checkpoint-600\n",
      "2022-12-23 18:45:01,655\tINFO trainable.py:503 -- Current state after restoring: {'_iteration': 600, '_timesteps_total': 2400000, '_time_total': 3243.9897010326385, '_episodes_total': 1697}\n"
     ]
    }
   ],
   "source": [
    "# Restore the PPO agent from the last checkpoint file and save it in a variable called agent\n",
    "\n",
    "import ray\n",
    "\n",
    "ray.init()\n",
    "\n",
    "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
    "\n",
    "agent = PPOTrainer(config={\"env\": \"BipedalWalker-v3\",\n",
    "                           \"evaluation_interval\": 100,\n",
    "                           \"evaluation_num_episodes\": 100\n",
    "                           }\n",
    "                   )\n",
    "agent.restore(\"../../18_saving_the_trained_agent/exercises/bipedal_walker_v3/PPO/PPO_BipedalWalker-v3_a08d1_00000_0_2022-12-23_17-45-46/checkpoint_000600/checkpoint-600\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e2bf2-a9d2-48df-8c80-a0f957213564",
   "metadata": {},
   "source": [
    "Once we have a restored agent, we simply need to use `gym`'s video recorder to record a video.\n",
    "\n",
    "- You need to import gym's video recorder class and wrap the `BipedalWalker-v3` environment (this makes the environment video capable)\n",
    "- Make sure you store the video in a folder with the relative path `bipedal_walker_video`\n",
    "- Use the restored agent to take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e5af67-0947-4425-ad5e-11b39a2b9e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-23 18:45:45,401\tWARNING deprecation.py:45 -- DeprecationWarning: `compute_action` has been deprecated. Use `Trainer.compute_single_action()` instead. This will raise an error in the future!\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# Import the video recorder class below\n",
    "from gym.wrappers import RecordVideo\n",
    "\n",
    "\n",
    "# Crete a video capable `BipedalWalker-v3` environment\n",
    "env = RecordVideo(gym.make(\"BipedalWalker-v3\"), \"ppo_video\")    # The videos should be saved to the relative path bipedal_walker_video\n",
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action = agent.compute_action(obs)    # Compute the action according to the restored agent's policy\n",
    "    obs, r, done, _ = env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04dc847-667e-4107-8366-ea3e8f04eec2",
   "metadata": {},
   "source": [
    "Now just go to the `bipedal_walker_video` folder and play the mp4 file. \n",
    "\n",
    "Amazing, isn't it? You just taught this robot how to walk from scratch. That's no mean feat. Congratulations!\n",
    "\n",
    "You can use the same procedure to solve other environments in `gym`. If you are feeling adventurous, give `CarRacing-v0` and `LunarLander-v2` a try, for example."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastdeeprl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "3459b9ee942700531a18d492429a9fe85b9c36838acb44b82bdd23029e5b5b5f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
